{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"DDDQN.ipynb","provenance":[],"collapsed_sections":["9u_bVI_99Rfv","j4SkkGZU9Dd_","B9mN3hsv9Hl2","APhMTaPP9Kxl"]},"kernelspec":{"display_name":"reinforcement-learning","language":"python","name":"reinforcement-learning"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"},"widgets":{"application/vnd.jupyter.widget-state+json":{"daafc24804774e92b4f5d70219894488":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_b2f88fd9cd9d40939969cb11582bb03f","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_eb4d168039c54d98a743f559e0a57a0b","IPY_MODEL_a839dc8d0e654894b65df1e73d951c86","IPY_MODEL_dd7bb126215e460984f991f0a939ebfa"]}},"b2f88fd9cd9d40939969cb11582bb03f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"eb4d168039c54d98a743f559e0a57a0b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_fad52d2922884beda30065777afbb8b7","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"  7%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_11e642c26adf4b7883976a7d2a61eaab"}},"a839dc8d0e654894b65df1e73d951c86":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_c055da85f6314064b94d232f45587068","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"danger","max":5702,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":406,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_30604b30cf1a4861b5b9df8824d445a4"}},"dd7bb126215e460984f991f0a939ebfa":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_e1e227ac4f6748318cd4344faa36e160","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 406/5702 [1:47:24&lt;23:21:04, 15.87s/it]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_69960b0495dd4dd29536fc662b558e48"}},"fad52d2922884beda30065777afbb8b7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"11e642c26adf4b7883976a7d2a61eaab":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"c055da85f6314064b94d232f45587068":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"30604b30cf1a4861b5b9df8824d445a4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"e1e227ac4f6748318cd4344faa36e160":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"69960b0495dd4dd29536fc662b558e48":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"code","metadata":{"id":"k4n_BaeJzDsS","executionInfo":{"status":"ok","timestamp":1603273303854,"user_tz":-330,"elapsed":13039,"user":{"displayName":"Nimish S","photoUrl":"","userId":"16860995465865824316"}}},"source":["%%capture\n","!pip install gym_super_mario_bros"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"Zpgt8My59Q0t","executionInfo":{"status":"ok","timestamp":1603273332128,"user_tz":-330,"elapsed":41298,"user":{"displayName":"Nimish S","photoUrl":"","userId":"16860995465865824316"}},"outputId":"ef2637f4-ecb0-4f77-9d8a-7ed88a42d516","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"NER4VNsJ9Vgo","executionInfo":{"status":"ok","timestamp":1603273424413,"user_tz":-330,"elapsed":856,"user":{"displayName":"Nimish S","photoUrl":"","userId":"16860995465865824316"}}},"source":["ROOT = '/content/drive/My Drive/Practice/RL/SuperMario/DDDQN/weights'"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"KLAOgs3gOPy8","executionInfo":{"status":"ok","timestamp":1603273429704,"user_tz":-330,"elapsed":4882,"user":{"displayName":"Nimish S","photoUrl":"","userId":"16860995465865824316"}}},"source":["import os\n","import cv2\n","import gym\n","import time\n","import collections\n","\n","import numpy as np\n","import torch as T\n","import torch.optim as optim\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import matplotlib.pyplot as plt\n","\n","from tqdm.notebook import tqdm\n","\n","import gym_super_mario_bros\n","from nes_py.wrappers import JoypadSpace\n","from gym_super_mario_bros.actions import SIMPLE_MOVEMENT\n","\n","%matplotlib inline"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"rZDPJ0g-e6fh","executionInfo":{"status":"ok","timestamp":1603273454787,"user_tz":-330,"elapsed":991,"user":{"displayName":"Nimish S","photoUrl":"","userId":"16860995465865824316"}},"outputId":"7267f50b-0b23-4b26-c5af-01c5dd29fbb6","colab":{"base_uri":"https://localhost:8080/","height":36}},"source":["T.cuda.get_device_name()"],"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'Tesla T4'"]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"markdown","metadata":{"id":"9u_bVI_99Rfv"},"source":["## **Wrappers**"]},{"cell_type":"code","metadata":{"id":"L5aHWPN-OEAJ","executionInfo":{"status":"ok","timestamp":1603273455139,"user_tz":-330,"elapsed":1337,"user":{"displayName":"Nimish S","photoUrl":"","userId":"16860995465865824316"}}},"source":["# PREPROCESS EACH FRAME\n","class PreprocessFrames(gym.ObservationWrapper):\n","    \"\"\"\n","    PREPROCESSES EACH FRAME (input = (rows, columns, 3)) [0-255]\n","    1. resize image                             -   (new_rows, new_columns, 1)       [0-255]\n","    2. convert to nparray                       -   array(new_rows, new_columns, )  [0-255]\n","    3. move axis(reshape)                       -   array(1, new_rows, new_columns)  [0-255]\n","    3. scale values from 0-1                    -   array(1, new_rows, new_columns)  [0.0-1.0]\n","    \"\"\"\n","    def __init__(self, env, new_observation_shape):\n","        super().__init__(env)\n","        self.new_observation_shape = new_observation_shape\n","        self.observation_space = gym.spaces.Box(low=0.0, high=1.0, shape=self.new_observation_shape, dtype=np.float32)\n","    \n","    def observation(self, observation):\n","        temp_frame = cv2.cvtColor(observation, cv2.COLOR_RGB2GRAY)\n","        temp_frame = cv2.resize(temp_frame, self.new_observation_shape[1:], interpolation=cv2.INTER_AREA)\n","        new_observation = np.array(temp_frame, dtype=np.float32).reshape(self.new_observation_shape)\n","        new_observation = new_observation / 255.0 \n","        return new_observation\n","\n","# TO BE CALLED ON EACH SINGLE IMAGE (AFTER PREPROCESS)\n","class CustomStep(gym.Wrapper):\n","    \"\"\"\n","    OVERRIDES step() & reset()\n","    1. repeats same action in 'n' skipped frames to compute faster.\n","    2. takes maximum of 2 frames.\n","    \"\"\"\n","    def __init__(self, env, frame_skip):\n","        super().__init__(env)\n","        self.frame_skip = frame_skip\n","        self.observation_shape = env.observation_space.shape\n","        self.observation_buffer = np.zeros_like((2, self.observation_shape))\n","\n","    def reset(self):\n","        observation = self.env.reset()\n","        self.observation_buffer = np.zeros_like((2, self.observation_shape))\n","        self.observation_buffer[0] = observation\n","        return observation\n","\n","    # RETURN FRAME_SKIPPED FRAMES\n","    def step(self, action):\n","        total_reward = 0.0\n","        done = False\n","\n","        for frame in range(self.frame_skip):\n","            observation, reward, done, info = self.env.step(action)\n","            total_reward += reward\n","\n","            idx = frame % 2\n","            self.observation_buffer[idx] = observation\n","\n","            if done: break\n","\n","        observation_max = np.maximum(self.observation_buffer[0], self.observation_buffer[1])\n","        return observation_max, total_reward, done, info\n","\n","\n","# STACK OBSERVATIONS\n","class StackFrames(gym.ObservationWrapper):\n","    \"\"\"\n","    STACKS stack_size FRAMES TOGETHER AND RETURNS AS THE 'observation'\n","    1. on reset() returns first 'observation' STACKED 'stack_size' times\n","    2. observation() returns current 'observation' STACKED with 'stack_size-1' previous 'observation'\n","    \"\"\"\n","    def __init__(self, env, stack_size):\n","        super().__init__(env)\n","        self.observation_space = gym.spaces.Box(\n","                                    env.observation_space.low.repeat(stack_size, axis=0),\n","                                    env.observation_space.high.repeat(stack_size, axis=0)\n","                                 )\n","        self.stack = collections.deque(maxlen=stack_size)\n","\n","    def reset(self):\n","        self.stack.clear()\n","        observation = self.env.reset()\n","        for _ in range(self.stack.maxlen):\n","            self.stack.append(observation)\n","        observation = np.array(self.stack).reshape(self.observation_space.shape)\n","        return observation\n","        \n","    def observation(self, observation):\n","        self.stack.append(observation)\n","        observation = np.array(self.stack).reshape(self.observation_space.shape)\n","        return observation\n","\n","class CustomReward(gym.Wrapper):\n","    def __init__(self, env):\n","        super().__init__(env)\n","        self._current_score = 0\n","\n","    def step(self, action):\n","        observation, reward, done, info = self.env.step(action)\n","        reward += (info['score'] - self._current_score) / 40.0\n","        self._current_score = info['score']\n","        if done:\n","            if info['flag_get']:\n","                reward += 350.0\n","            else:\n","                reward -= 50.0\n","        return observation, reward / 10.0, done, info"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"R9YVrXJ0A0nd","executionInfo":{"status":"ok","timestamp":1603273455142,"user_tz":-330,"elapsed":1335,"user":{"displayName":"Nimish S","photoUrl":"","userId":"16860995465865824316"}}},"source":["# TIE EVERYTHING TOGETHER\n","def make_env(env_name, new_observation_shape=(1,96,96), stack_size=4, frame_skip=4):\n","    env = gym.make(env_name)\n","    env = JoypadSpace(env, SIMPLE_MOVEMENT)\n","    env = PreprocessFrames(env, new_observation_shape=new_observation_shape)\n","    env = CustomStep(env, frame_skip=4)\n","    env = StackFrames(env, stack_size=stack_size)\n","    env = CustomReward(env)\n","    return env"],"execution_count":11,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"j4SkkGZU9Dd_"},"source":["## **ReplayBuffer**"]},{"cell_type":"code","metadata":{"id":"-SvHE9YKo0r-","executionInfo":{"status":"ok","timestamp":1603273455756,"user_tz":-330,"elapsed":1943,"user":{"displayName":"Nimish S","photoUrl":"","userId":"16860995465865824316"}}},"source":["class ReplayBuffer:\n","    def __init__(self, mem_size, observation_shape, n_actions):\n","        self.mem_size = mem_size\n","        self.mem_counter = 0\n","        # DATA\n","        self.states = np.zeros((mem_size, *observation_shape), dtype=np.float32)\n","        self.actions = np.zeros(mem_size, dtype=np.int64)\n","        self.rewards = np.zeros(mem_size, dtype=np.int64)\n","        self.states_ = np.zeros((mem_size, *observation_shape), dtype=np.float32)\n","        self.terminals = np.zeros(mem_size, dtype=bool)\n","\n","    # STORE TRANSITIONS IN BUFFER\n","    def store_transition(self, state, action, reward, state_, done):\n","        index = self.mem_counter % self.mem_size\n","        self.states[index] = state\n","        self.actions[index] = action\n","        self.rewards[index] = reward\n","        self.states_[index] = state_\n","        self.terminals[index] = done # 1 if 'done' else 0\n","        self.mem_counter += 1\n","\n","    # UNIFORMLY SAMPLES 'BUFFER' AND RETURNS A 'BATCH' OF batch_size\n","    def sample_batch(self, batch_size):\n","        max_index = min(self.mem_counter, self.mem_size)\n","        batch_indices = np.random.choice(max_index, batch_size, replace=False)\n","        states = self.states[batch_indices]\n","        actions = self.actions[batch_indices]\n","        rewards = self.rewards[batch_indices]\n","        states_ = self.states_[batch_indices]\n","        terminals = self.terminals[batch_indices]\n","        return (states, actions, rewards, states_, terminals)"],"execution_count":12,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"B9mN3hsv9Hl2"},"source":["## **Network**"]},{"cell_type":"code","metadata":{"id":"N4-yaJCQ0Kci","executionInfo":{"status":"ok","timestamp":1603273465443,"user_tz":-330,"elapsed":779,"user":{"displayName":"Nimish S","photoUrl":"","userId":"16860995465865824316"}}},"source":["class DuelingDeepQNetwork(nn.Module):\n","    def __init__(self, lr, observation_shape, n_actions, model_name, model_dir):\n","        super().__init__()\n","        self.model_dir = model_dir\n","        self.model_file = os.path.join(self.model_dir, model_name)\n","        # CNN\n","        self.conv1 = nn.Conv2d(observation_shape[0], 32, kernel_size=8, stride=4)\n","        self.conv2 = nn.Conv2d(32, 64, kernel_size=4, stride=2)\n","        self.conv3 = nn.Conv2d(64, 64, kernel_size=3, stride=1)\n","        # CNN -> ANN\n","        fc_input_dims = self.caculate_conv_output_dims(observation_shape)\n","        # ANN\n","        self.fc1 = nn.Linear(fc_input_dims, 512)\n","        # DUELING\n","        self.V = nn.Linear(512, 1)\n","        self.A = nn.Linear(512, n_actions)\n","        # UTILS\n","        self.device = T.device('cuda:0' if T.cuda.is_available() else 'cpu')\n","        self.optimizer = optim.RMSprop(self.parameters(), lr=lr)\n","        self.loss = nn.SmoothL1Loss() # CUSTOM LOSS IN AGENT\n","        self.to(self.device)\n","    \n","    def forward(self, state):\n","        t = F.relu(self.conv1(state))\n","        t = F.relu(self.conv2(t))\n","        t = F.relu(self.conv3(t))\n","        t = F.relu(self.fc1(t.reshape(t.shape[0], -1)))\n","        V = self.V(t)\n","        A = self.A(t)\n","        return V,A\n","\n","    def caculate_conv_output_dims(self, observation_shape):\n","        dims = T.zeros((1, *observation_shape))\n","        dims = self.conv1(dims)\n","        dims = self.conv2(dims)\n","        dims = self.conv3(dims)\n","        return int(np.prod(dims.shape))\n","\n","    def save_model(self):\n","        print(\"[INFO] Saving model\")\n","        checkpoint = {\n","            'model_state_dict': self.state_dict(),\n","            'optimizer_state_dict' : self.optimizer.state_dict()\n","        }\n","        T.save(checkpoint, self.model_file)\n","    \n","    def load_model(self, cpu=False):\n","        print(\"[INFO] Loading model\")\n","        \n","        map_location = T.device('cpu') if (cpu) else None\n","        \n","        checkpoint = T.load(self.model_file, map_location=map_location)\n","        self.load_state_dict(checkpoint['model_state_dict'])\n","        self.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])"],"execution_count":16,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"APhMTaPP9Kxl"},"source":["## **Agent**"]},{"cell_type":"code","metadata":{"id":"Jf105mZ2pb8I","executionInfo":{"status":"ok","timestamp":1603273455759,"user_tz":-330,"elapsed":1937,"user":{"displayName":"Nimish S","photoUrl":"","userId":"16860995465865824316"}}},"source":["class DuelingDDQNAgent:\n","    def __init__(self, observation_shape, n_actions, lr, gamma, epsilon, epsilon_min, epsilon_decay, mem_size,  batch_size, \n","                 Q_TARGET_replace_interval, initial_exploration_steps, algo_name, env_name, model_dir):\n","        self.observation_shape = observation_shape\n","        self.n_actions = n_actions\n","        self.LR = lr\n","        self.GAMMA = gamma\n","        self.EPSILON = epsilon\n","        self.epsilon_min = epsilon_min\n","        self.epsilon_decay = epsilon_decay\n","\n","        # MEM PARAMS\n","        self.mem_size = mem_size\n","        self.batch_size = batch_size\n","        self.memory = ReplayBuffer(mem_size, observation_shape, n_actions)\n","\n","        # MODEL PARAMS\n","        self.initial_exploration_steps = initial_exploration_steps\n","        self.exploration_counter = 0\n","        self.learn_counter = 0 # TO UPDATE TARGET NETWORK\n","        self.algo_name = algo_name\n","        self.env_name = env_name\n","        self.model_dir = model_dir\n","        self.Q_TARGET_replace_interval = Q_TARGET_replace_interval\n","        # Q1\n","        self.Q_STEP = DuelingDeepQNetwork(lr, observation_shape, n_actions,\n","                              model_name = env_name+'_'+algo_name+'_Q_STEP',\n","                              model_dir = model_dir)\n","        # Q2\n","        self.Q_TARGET = DuelingDeepQNetwork(lr, observation_shape, n_actions,\n","                              model_name = env_name+'_'+algo_name+'_Q_TARGET',\n","                              model_dir = model_dir)\n","\n","    # e-GREEDY POLICY\n","    def get_action(self, observation, greedy=False):\n","        if ( (np.random.uniform() >= self.EPSILON) or greedy):\n","            observation = T.tensor(observation, dtype=T.float32).to(self.Q_STEP.device)\n","            state = T.unsqueeze(observation, 0)\n","            _,A = self.Q_STEP(state)\n","            action = T.argmax(A).item()\n","        else:\n","            action = env.action_space.sample()\n","        return action\n","\n","    def learn(self):\n","        if (self.exploration_counter < self.initial_exploration_steps): return # return if not explored enough\n","        if (self.memory.mem_counter < self.batch_size): return # return if insufficient samples present\n","        # RESET TARGET NETWORK (every 1000 steps)\n","        self.update_Q_TARGET()\n","\n","        states, actions, rewards, states_, terminals = self.sample_batch()\n","        # PREDICT Q1(s,a)\n","        v1,a1 = self.Q_STEP(states)\n","        q1 = v1 + (a1 - a1.mean(dim=1, keepdim=True)) # q - batch_size * n_actions\n","        indices = np.arange(len(actions))\n","        q1_preds = q1[indices,actions]\n","\n","        # GET V1,A2(s_,A) and V2,A2(s_,A)\n","        v1_, a1_ = self.Q_STEP(states_)\n","        v2_, a2_ = self.Q_TARGET(states_)\n","        # GET Q1(s_,A) and Q2(s_,A)\n","        q1_ = v1_ + (a1_ - a1_.mean(dim=1, keepdim=True))\n","        q2_ = v2_ + (a2_ - a2_.mean(dim=1, keepdim=True))\n","        # argmax(Q1(s_,A)) - (max)a_\n","        # Q2(s_, (max)a_) - TARGETS\n","        a_ = T.argmax(q1_, dim=1)\n","        indices = np.arange(len(a_))\n","        q2_next = q2_[indices, a_]\n","        q2_next[terminals] = 0.0                      # Q2(s_) = 0 where terminal=1\n","        q2_targets = rewards + (self.GAMMA * q2_next)\n","\n","        # CALC LOSS & BACKPROP\n","        loss = self.Q_TARGET.loss(q1_preds, q2_targets).to(self.Q_STEP.device)\n","        # loss = loss.mean()\n","\n","        self.Q_STEP.optimizer.zero_grad()\n","        loss.backward()\n","        self.Q_STEP.optimizer.step()\n","\n","        self.learn_counter += 1\n","        self.decay_epsilon()\n","\n","    def update_Q_TARGET(self):\n","        if ((self.learn_counter % self.Q_TARGET_replace_interval) == 0):\n","            self.Q_TARGET.load_state_dict(self.Q_STEP.state_dict())\n","    \n","    def decay_epsilon(self):\n","        if (self.EPSILON > self.epsilon_min):\n","            self.EPSILON -= self.epsilon_decay\n","        else:\n","            self.EPSILON = self.epsilon_min\n","    \n","    def store_transition(self, state, action, reward, state_, done):\n","        self.memory.store_transition(state, action, reward, state_, done)\n","\n","    def sample_batch(self):\n","        states, actions, rewards, states_, terminals = self.memory.sample_batch(self.batch_size)\n","        states = T.tensor(states).to(self.Q_STEP.device)\n","        actions = T.tensor(actions).to(self.Q_STEP.device)\n","        rewards = T.tensor(rewards).to(self.Q_STEP.device)\n","        states_ = T.tensor(states_).to(self.Q_STEP.device)\n","        terminals = T.tensor(terminals).to(self.Q_STEP.device)\n","        return states, actions, rewards, states_, terminals\n","        \n","    def save_models(self):\n","        self.Q_STEP.save_model()\n","        self.Q_TARGET.save_model()\n","    \n","    def load_models(self, cpu=False):\n","        self.Q_STEP.load_model(cpu)\n","        self.Q_TARGET.load_model(cpu)"],"execution_count":14,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"g7HQrV3WcH2c"},"source":["## **Training**"]},{"cell_type":"code","metadata":{"id":"mj6YZi0aXsDX","executionInfo":{"status":"ok","timestamp":1603273456127,"user_tz":-330,"elapsed":2300,"user":{"displayName":"Nimish S","photoUrl":"","userId":"16860995465865824316"}}},"source":["env_name = 'SuperMarioBros-1-1-v0'\n","env = make_env(env_name)\n","# ROOT = './'\n","\n","# SIMPLE_MOVEMENT = [\n","#     ['NOOP'],\n","#     ['right'],\n","#     ['right', 'A'],\n","#     ['right', 'B'],\n","#     ['right', 'A', 'B'],\n","#     ['A'],\n","#     ['left'],\n","# ]"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"id":"4xxXF9QF3xdG","executionInfo":{"status":"ok","timestamp":1603273511728,"user_tz":-330,"elapsed":13528,"user":{"displayName":"Nimish S","photoUrl":"","userId":"16860995465865824316"}}},"source":["agent = DuelingDDQNAgent(observation_shape=env.observation_space.shape,\n","                         n_actions=env.action_space.n,\n","                         lr=1e-4,\n","                         gamma=0.99,\n","                         epsilon=1.0,\n","                         epsilon_min=0.01,\n","                         epsilon_decay=1e-6,\n","                         mem_size=20000,\n","                         batch_size=32,\n","                         Q_TARGET_replace_interval=1000,\n","                         initial_exploration_steps = 10000,\n","                         algo_name='DuelingDDQN',\n","                         env_name=env_name,\n","                         model_dir=ROOT)"],"execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"id":"RPOBUYlc7eOq","executionInfo":{"status":"ok","timestamp":1603273517049,"user_tz":-330,"elapsed":2894,"user":{"displayName":"Nimish S","photoUrl":"","userId":"16860995465865824316"}},"outputId":"86b67ad0-e1f6-4544-f019-7e1ef5489d59","colab":{"base_uri":"https://localhost:8080/","height":52}},"source":["# ## IF NEW TRAIN CYCLE\n","# N_EPISODES = 10000\n","\n","# best_reward = -np.inf\n","# episode_rewards, episode_lengths, episode_epsilons, mean_rewards = [],[],[],[]\n","\n","## IF SERIALIZED OBJECT EXISTS\n","train_metadata = T.load((ROOT+\"/train_metadata-1-1.pkl\"))\n","\n","N_EPISODES = 10000 - train_metadata[\"episode_n\"]\n","best_reward = train_metadata[\"best_reward\"]\n","episode_rewards = train_metadata[\"episode_rewards\"]\n","episode_lengths = train_metadata[\"episode_lengths\"]\n","episode_epsilons = train_metadata[\"episode_epsilons\"]\n","mean_rewards = train_metadata[\"mean_rewards\"]\n","\n","agent.EPSILON = episode_epsilons[len(episode_epsilons)-1]\n","agent.load_models()"],"execution_count":19,"outputs":[{"output_type":"stream","text":["[INFO] Loading model\n","[INFO] Loading model\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Rp2We9miezCT","executionInfo":{"status":"error","timestamp":1603279991232,"user_tz":-330,"elapsed":6445822,"user":{"displayName":"Nimish S","photoUrl":"","userId":"16860995465865824316"}},"outputId":"257b1c1a-54a1-4563-c7af-ecdb05443d53","colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["daafc24804774e92b4f5d70219894488","b2f88fd9cd9d40939969cb11582bb03f","eb4d168039c54d98a743f559e0a57a0b","a839dc8d0e654894b65df1e73d951c86","dd7bb126215e460984f991f0a939ebfa","fad52d2922884beda30065777afbb8b7","11e642c26adf4b7883976a7d2a61eaab","c055da85f6314064b94d232f45587068","30604b30cf1a4861b5b9df8824d445a4","e1e227ac4f6748318cd4344faa36e160","69960b0495dd4dd29536fc662b558e48"]}},"source":["for episode_n in tqdm(range(N_EPISODES)):\n","    total_reward, total_moves = 0,0\n","\n","    done = False\n","    observation = env.reset()\n","\n","    while not done:\n","        agent.exploration_counter += 1\n","        # e-GREEDY ACTION\n","        action = agent.get_action(observation)\n","        observation_, reward, done, _ = env.step(action)\n","\n","        total_reward += reward\n","        total_moves += 1\n","\n","        # STORE DATA & LEARN\n","        agent.store_transition(observation, action, reward, observation_, done)\n","        agent.learn()\n","\n","        observation = observation_\n","\n","    episode_rewards.append(total_reward)\n","    episode_lengths.append(total_moves)\n","    episode_epsilons.append(agent.EPSILON)\n","\n","    mean_reward = np.mean(episode_rewards[-100:])\n","    mean_rewards.append(mean_reward)\n","    \n","    if(mean_reward > best_reward):\n","        agent.save_models()\n","        best_reward = mean_reward\n","\n","        train_metadata = {\n","            'episode_n': episode_n,\n","            'best_reward': best_reward,\n","            'mean_rewards': mean_rewards,\n","            'episode_rewards': episode_rewards, \n","            'episode_lengths': episode_lengths,\n","            'episode_epsilons': episode_epsilons\n","        }\n","        T.save(train_metadata, (ROOT+\"/train_metadata-1-1.pkl\"))\n","\n","    print(\"ITER: \",episode_n,\"\\tRWD: \",round(total_reward,2),\"\\tM_RWD: \",round(mean_reward,2),\"\\tLEN: \",total_moves,\"\\tEPS: \",round(agent.EPSILON,4))"],"execution_count":20,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"daafc24804774e92b4f5d70219894488","version_minor":0,"version_major":2},"text/plain":["HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=5702.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["ITER:  0 \tRWD:  188.5 \tM_RWD:  173.68 \tLEN:  190 \tEPS:  0.0165\n","ITER:  1 \tRWD:  166.95 \tM_RWD:  173.47 \tLEN:  157 \tEPS:  0.0165\n","ITER:  2 \tRWD:  75.45 \tM_RWD:  171.91 \tLEN:  133 \tEPS:  0.0165\n","ITER:  3 \tRWD:  189.75 \tM_RWD:  173.64 \tLEN:  180 \tEPS:  0.0165\n","ITER:  4 \tRWD:  182.55 \tM_RWD:  173.77 \tLEN:  186 \tEPS:  0.0165\n","ITER:  5 \tRWD:  67.0 \tM_RWD:  172.62 \tLEN:  78 \tEPS:  0.0165\n","ITER:  6 \tRWD:  188.65 \tM_RWD:  173.92 \tLEN:  182 \tEPS:  0.0165\n","ITER:  7 \tRWD:  189.05 \tM_RWD:  172.61 \tLEN:  183 \tEPS:  0.0165\n","ITER:  8 \tRWD:  185.0 \tM_RWD:  172.96 \tLEN:  187 \tEPS:  0.0165\n","ITER:  9 \tRWD:  54.75 \tM_RWD:  171.63 \tLEN:  65 \tEPS:  0.0165\n","ITER:  10 \tRWD:  329.95 \tM_RWD:  173.28 \tLEN:  922 \tEPS:  0.0165\n","ITER:  11 \tRWD:  187.65 \tM_RWD:  173.26 \tLEN:  182 \tEPS:  0.0165\n","ITER:  12 \tRWD:  228.6 \tM_RWD:  173.48 \tLEN:  389 \tEPS:  0.0165\n","ITER:  13 \tRWD:  166.5 \tM_RWD:  173.87 \tLEN:  162 \tEPS:  0.0165\n","[INFO] Saving model\n","[INFO] Saving model\n","ITER:  14 \tRWD:  183.6 \tM_RWD:  175.14 \tLEN:  180 \tEPS:  0.0165\n","ITER:  15 \tRWD:  186.45 \tM_RWD:  174.45 \tLEN:  187 \tEPS:  0.0165\n","ITER:  16 \tRWD:  75.65 \tM_RWD:  173.42 \tLEN:  147 \tEPS:  0.0165\n","ITER:  17 \tRWD:  189.2 \tM_RWD:  173.67 \tLEN:  187 \tEPS:  0.0165\n","ITER:  18 \tRWD:  230.4 \tM_RWD:  174.96 \tLEN:  285 \tEPS:  0.0165\n","[INFO] Saving model\n","[INFO] Saving model\n","ITER:  19 \tRWD:  230.65 \tM_RWD:  175.4 \tLEN:  290 \tEPS:  0.0165\n","ITER:  20 \tRWD:  167.25 \tM_RWD:  175.19 \tLEN:  162 \tEPS:  0.0165\n","ITER:  21 \tRWD:  188.0 \tM_RWD:  175.2 \tLEN:  183 \tEPS:  0.0165\n","[INFO] Saving model\n","[INFO] Saving model\n","ITER:  22 \tRWD:  187.4 \tM_RWD:  175.54 \tLEN:  182 \tEPS:  0.0165\n","[INFO] Saving model\n","[INFO] Saving model\n","ITER:  23 \tRWD:  187.4 \tM_RWD:  175.54 \tLEN:  182 \tEPS:  0.0165\n","[INFO] Saving model\n","[INFO] Saving model\n","ITER:  24 \tRWD:  187.4 \tM_RWD:  175.55 \tLEN:  182 \tEPS:  0.0165\n","ITER:  25 \tRWD:  187.6 \tM_RWD:  175.15 \tLEN:  179 \tEPS:  0.0165\n","[INFO] Saving model\n","[INFO] Saving model\n","ITER:  26 \tRWD:  231.6 \tM_RWD:  175.81 \tLEN:  228 \tEPS:  0.0165\n","[INFO] Saving model\n","[INFO] Saving model\n","ITER:  27 \tRWD:  187.9 \tM_RWD:  177.52 \tLEN:  182 \tEPS:  0.0165\n","[INFO] Saving model\n","[INFO] Saving model\n","ITER:  28 \tRWD:  321.6 \tM_RWD:  178.43 \tLEN:  1328 \tEPS:  0.0165\n","[INFO] Saving model\n","[INFO] Saving model\n","ITER:  29 \tRWD:  230.65 \tM_RWD:  178.89 \tLEN:  248 \tEPS:  0.0165\n","[INFO] Saving model\n","[INFO] Saving model\n","ITER:  30 \tRWD:  188.3 \tM_RWD:  179.11 \tLEN:  184 \tEPS:  0.0165\n","ITER:  31 \tRWD:  187.15 \tM_RWD:  179.09 \tLEN:  182 \tEPS:  0.0165\n","ITER:  32 \tRWD:  164.2 \tM_RWD:  178.42 \tLEN:  161 \tEPS:  0.0165\n","[INFO] Saving model\n","[INFO] Saving model\n","ITER:  33 \tRWD:  335.9 \tM_RWD:  180.52 \tLEN:  736 \tEPS:  0.0165\n","ITER:  34 \tRWD:  164.6 \tM_RWD:  180.52 \tLEN:  166 \tEPS:  0.0165\n","[INFO] Saving model\n","[INFO] Saving model\n","ITER:  35 \tRWD:  186.9 \tM_RWD:  180.75 \tLEN:  192 \tEPS:  0.0165\n","ITER:  36 \tRWD:  53.9 \tM_RWD:  179.49 \tLEN:  77 \tEPS:  0.0165\n","ITER:  37 \tRWD:  189.3 \tM_RWD:  178.79 \tLEN:  178 \tEPS:  0.0165\n","ITER:  38 \tRWD:  220.6 \tM_RWD:  179.37 \tLEN:  820 \tEPS:  0.0163\n","ITER:  39 \tRWD:  187.05 \tM_RWD:  179.36 \tLEN:  186 \tEPS:  0.0161\n","[INFO] Saving model\n","[INFO] Saving model\n","ITER:  40 \tRWD:  334.15 \tM_RWD:  180.83 \tLEN:  687 \tEPS:  0.0154\n","ITER:  41 \tRWD:  96.65 \tM_RWD:  179.92 \tLEN:  104 \tEPS:  0.0153\n","ITER:  42 \tRWD:  176.4 \tM_RWD:  179.46 \tLEN:  502 \tEPS:  0.0148\n","ITER:  43 \tRWD:  184.4 \tM_RWD:  180.54 \tLEN:  183 \tEPS:  0.0146\n","ITER:  44 \tRWD:  230.5 \tM_RWD:  180.54 \tLEN:  275 \tEPS:  0.0143\n","ITER:  45 \tRWD:  54.85 \tM_RWD:  180.11 \tLEN:  58 \tEPS:  0.0143\n","ITER:  46 \tRWD:  181.6 \tM_RWD:  180.23 \tLEN:  182 \tEPS:  0.0141\n","ITER:  47 \tRWD:  56.3 \tM_RWD:  179.81 \tLEN:  73 \tEPS:  0.014\n","ITER:  48 \tRWD:  166.6 \tM_RWD:  179.16 \tLEN:  152 \tEPS:  0.0138\n","ITER:  49 \tRWD:  185.3 \tM_RWD:  179.19 \tLEN:  184 \tEPS:  0.0137\n","ITER:  50 \tRWD:  164.25 \tM_RWD:  179.45 \tLEN:  152 \tEPS:  0.0135\n","ITER:  51 \tRWD:  162.9 \tM_RWD:  179.67 \tLEN:  235 \tEPS:  0.0133\n","ITER:  52 \tRWD:  189.05 \tM_RWD:  179.79 \tLEN:  174 \tEPS:  0.0131\n","ITER:  53 \tRWD:  38.8 \tM_RWD:  179.59 \tLEN:  2005 \tEPS:  0.0111\n","ITER:  54 \tRWD:  188.25 \tM_RWD:  179.58 \tLEN:  173 \tEPS:  0.0109\n","ITER:  55 \tRWD:  163.55 \tM_RWD:  179.6 \tLEN:  165 \tEPS:  0.0108\n","ITER:  56 \tRWD:  182.0 \tM_RWD:  179.15 \tLEN:  168 \tEPS:  0.0106\n","ITER:  57 \tRWD:  176.85 \tM_RWD:  180.17 \tLEN:  193 \tEPS:  0.0104\n","ITER:  58 \tRWD:  166.05 \tM_RWD:  179.94 \tLEN:  154 \tEPS:  0.0102\n","ITER:  59 \tRWD:  156.85 \tM_RWD:  179.67 \tLEN:  198 \tEPS:  0.01\n","ITER:  60 \tRWD:  187.55 \tM_RWD:  180.17 \tLEN:  176 \tEPS:  0.01\n","ITER:  61 \tRWD:  172.75 \tM_RWD:  180.02 \tLEN:  227 \tEPS:  0.01\n","ITER:  62 \tRWD:  179.0 \tM_RWD:  179.94 \tLEN:  266 \tEPS:  0.01\n","ITER:  63 \tRWD:  56.15 \tM_RWD:  178.84 \tLEN:  68 \tEPS:  0.01\n","ITER:  64 \tRWD:  231.75 \tM_RWD:  179.35 \tLEN:  254 \tEPS:  0.01\n","ITER:  65 \tRWD:  172.15 \tM_RWD:  179.19 \tLEN:  244 \tEPS:  0.01\n","ITER:  66 \tRWD:  181.0 \tM_RWD:  178.7 \tLEN:  185 \tEPS:  0.01\n","ITER:  67 \tRWD:  167.7 \tM_RWD:  179.4 \tLEN:  153 \tEPS:  0.01\n","ITER:  68 \tRWD:  167.8 \tM_RWD:  179.78 \tLEN:  154 \tEPS:  0.01\n","ITER:  69 \tRWD:  178.95 \tM_RWD:  179.93 \tLEN:  184 \tEPS:  0.01\n","ITER:  70 \tRWD:  177.85 \tM_RWD:  180.05 \tLEN:  196 \tEPS:  0.01\n","ITER:  71 \tRWD:  172.25 \tM_RWD:  179.46 \tLEN:  250 \tEPS:  0.01\n","ITER:  72 \tRWD:  175.9 \tM_RWD:  179.33 \tLEN:  230 \tEPS:  0.01\n","ITER:  73 \tRWD:  180.2 \tM_RWD:  178.93 \tLEN:  168 \tEPS:  0.01\n","ITER:  74 \tRWD:  174.1 \tM_RWD:  178.97 \tLEN:  230 \tEPS:  0.01\n","ITER:  75 \tRWD:  166.6 \tM_RWD:  178.82 \tLEN:  154 \tEPS:  0.01\n","ITER:  76 \tRWD:  180.55 \tM_RWD:  178.99 \tLEN:  187 \tEPS:  0.01\n","ITER:  77 \tRWD:  163.7 \tM_RWD:  178.98 \tLEN:  156 \tEPS:  0.01\n","ITER:  78 \tRWD:  188.2 \tM_RWD:  179.04 \tLEN:  176 \tEPS:  0.01\n","ITER:  79 \tRWD:  183.7 \tM_RWD:  179.05 \tLEN:  177 \tEPS:  0.01\n","ITER:  80 \tRWD:  178.75 \tM_RWD:  178.8 \tLEN:  199 \tEPS:  0.01\n","ITER:  81 \tRWD:  156.3 \tM_RWD:  178.98 \tLEN:  191 \tEPS:  0.01\n","ITER:  82 \tRWD:  166.3 \tM_RWD:  179.26 \tLEN:  155 \tEPS:  0.01\n","ITER:  83 \tRWD:  173.05 \tM_RWD:  178.67 \tLEN:  235 \tEPS:  0.01\n","ITER:  84 \tRWD:  180.7 \tM_RWD:  178.84 \tLEN:  170 \tEPS:  0.01\n","ITER:  85 \tRWD:  178.1 \tM_RWD:  178.73 \tLEN:  210 \tEPS:  0.01\n","ITER:  86 \tRWD:  171.55 \tM_RWD:  178.78 \tLEN:  273 \tEPS:  0.01\n","ITER:  87 \tRWD:  164.5 \tM_RWD:  178.17 \tLEN:  159 \tEPS:  0.01\n","ITER:  88 \tRWD:  181.95 \tM_RWD:  178.11 \tLEN:  181 \tEPS:  0.01\n","ITER:  89 \tRWD:  176.75 \tM_RWD:  178.01 \tLEN:  205 \tEPS:  0.01\n","ITER:  90 \tRWD:  167.9 \tM_RWD:  179.14 \tLEN:  175 \tEPS:  0.01\n","ITER:  91 \tRWD:  177.7 \tM_RWD:  179.11 \tLEN:  406 \tEPS:  0.01\n","ITER:  92 \tRWD:  169.85 \tM_RWD:  179.14 \tLEN:  420 \tEPS:  0.01\n","ITER:  93 \tRWD:  173.85 \tM_RWD:  179.0 \tLEN:  212 \tEPS:  0.01\n","ITER:  94 \tRWD:  140.6 \tM_RWD:  178.76 \tLEN:  133 \tEPS:  0.01\n","ITER:  95 \tRWD:  55.3 \tM_RWD:  177.54 \tLEN:  61 \tEPS:  0.01\n","ITER:  96 \tRWD:  56.45 \tM_RWD:  175.78 \tLEN:  65 \tEPS:  0.01\n","ITER:  97 \tRWD:  67.35 \tM_RWD:  174.14 \tLEN:  171 \tEPS:  0.01\n","ITER:  98 \tRWD:  181.7 \tM_RWD:  172.62 \tLEN:  209 \tEPS:  0.01\n","ITER:  99 \tRWD:  152.1 \tM_RWD:  172.35 \tLEN:  154 \tEPS:  0.01\n","ITER:  100 \tRWD:  183.5 \tM_RWD:  172.3 \tLEN:  178 \tEPS:  0.01\n","ITER:  101 \tRWD:  54.45 \tM_RWD:  171.17 \tLEN:  62 \tEPS:  0.01\n","ITER:  102 \tRWD:  185.35 \tM_RWD:  172.27 \tLEN:  187 \tEPS:  0.01\n","ITER:  103 \tRWD:  167.15 \tM_RWD:  172.05 \tLEN:  171 \tEPS:  0.01\n","ITER:  104 \tRWD:  173.7 \tM_RWD:  171.96 \tLEN:  234 \tEPS:  0.01\n","ITER:  105 \tRWD:  180.35 \tM_RWD:  173.09 \tLEN:  174 \tEPS:  0.01\n","ITER:  106 \tRWD:  181.1 \tM_RWD:  173.02 \tLEN:  199 \tEPS:  0.01\n","ITER:  107 \tRWD:  171.45 \tM_RWD:  172.84 \tLEN:  348 \tEPS:  0.01\n","ITER:  108 \tRWD:  97.85 \tM_RWD:  171.97 \tLEN:  106 \tEPS:  0.01\n","ITER:  109 \tRWD:  181.8 \tM_RWD:  173.24 \tLEN:  176 \tEPS:  0.01\n","ITER:  110 \tRWD:  182.35 \tM_RWD:  171.76 \tLEN:  193 \tEPS:  0.01\n","ITER:  111 \tRWD:  172.15 \tM_RWD:  171.61 \tLEN:  241 \tEPS:  0.01\n","ITER:  112 \tRWD:  172.5 \tM_RWD:  171.05 \tLEN:  257 \tEPS:  0.01\n","ITER:  113 \tRWD:  174.0 \tM_RWD:  171.12 \tLEN:  196 \tEPS:  0.01\n","ITER:  114 \tRWD:  179.4 \tM_RWD:  171.08 \tLEN:  198 \tEPS:  0.01\n","ITER:  115 \tRWD:  162.6 \tM_RWD:  170.84 \tLEN:  164 \tEPS:  0.01\n","ITER:  116 \tRWD:  178.35 \tM_RWD:  171.87 \tLEN:  188 \tEPS:  0.01\n","ITER:  117 \tRWD:  178.65 \tM_RWD:  171.76 \tLEN:  200 \tEPS:  0.01\n","ITER:  118 \tRWD:  162.6 \tM_RWD:  171.09 \tLEN:  159 \tEPS:  0.01\n","ITER:  119 \tRWD:  226.8 \tM_RWD:  171.05 \tLEN:  411 \tEPS:  0.01\n","ITER:  120 \tRWD:  152.9 \tM_RWD:  170.9 \tLEN:  142 \tEPS:  0.01\n","ITER:  121 \tRWD:  184.7 \tM_RWD:  170.87 \tLEN:  200 \tEPS:  0.01\n","ITER:  122 \tRWD:  182.4 \tM_RWD:  170.82 \tLEN:  203 \tEPS:  0.01\n","ITER:  123 \tRWD:  167.85 \tM_RWD:  170.62 \tLEN:  157 \tEPS:  0.01\n","ITER:  124 \tRWD:  178.4 \tM_RWD:  170.53 \tLEN:  195 \tEPS:  0.01\n","ITER:  125 \tRWD:  153.05 \tM_RWD:  170.19 \tLEN:  149 \tEPS:  0.01\n","ITER:  126 \tRWD:  186.1 \tM_RWD:  169.73 \tLEN:  2005 \tEPS:  0.01\n","ITER:  127 \tRWD:  181.75 \tM_RWD:  169.67 \tLEN:  189 \tEPS:  0.01\n","ITER:  128 \tRWD:  7.9 \tM_RWD:  166.54 \tLEN:  2005 \tEPS:  0.01\n","ITER:  129 \tRWD:  190.3 \tM_RWD:  166.13 \tLEN:  185 \tEPS:  0.01\n","ITER:  130 \tRWD:  183.4 \tM_RWD:  166.08 \tLEN:  2005 \tEPS:  0.01\n","ITER:  131 \tRWD:  66.95 \tM_RWD:  164.88 \tLEN:  102 \tEPS:  0.01\n","ITER:  132 \tRWD:  180.25 \tM_RWD:  165.04 \tLEN:  188 \tEPS:  0.01\n","ITER:  133 \tRWD:  163.5 \tM_RWD:  163.32 \tLEN:  165 \tEPS:  0.01\n","ITER:  134 \tRWD:  181.7 \tM_RWD:  163.49 \tLEN:  190 \tEPS:  0.01\n","ITER:  135 \tRWD:  189.3 \tM_RWD:  163.51 \tLEN:  191 \tEPS:  0.01\n","ITER:  136 \tRWD:  152.8 \tM_RWD:  164.5 \tLEN:  142 \tEPS:  0.01\n","ITER:  137 \tRWD:  153.7 \tM_RWD:  164.15 \tLEN:  141 \tEPS:  0.01\n","ITER:  138 \tRWD:  153.35 \tM_RWD:  163.47 \tLEN:  142 \tEPS:  0.01\n","ITER:  139 \tRWD:  176.15 \tM_RWD:  163.36 \tLEN:  210 \tEPS:  0.01\n","ITER:  140 \tRWD:  183.25 \tM_RWD:  161.86 \tLEN:  182 \tEPS:  0.01\n","ITER:  141 \tRWD:  136.8 \tM_RWD:  162.26 \tLEN:  132 \tEPS:  0.01\n","ITER:  142 \tRWD:  130.8 \tM_RWD:  161.8 \tLEN:  122 \tEPS:  0.01\n","ITER:  143 \tRWD:  169.2 \tM_RWD:  161.65 \tLEN:  153 \tEPS:  0.01\n","ITER:  144 \tRWD:  162.6 \tM_RWD:  160.97 \tLEN:  159 \tEPS:  0.01\n","ITER:  145 \tRWD:  153.9 \tM_RWD:  161.96 \tLEN:  143 \tEPS:  0.01\n","ITER:  146 \tRWD:  164.4 \tM_RWD:  161.79 \tLEN:  158 \tEPS:  0.01\n","ITER:  147 \tRWD:  181.2 \tM_RWD:  163.04 \tLEN:  173 \tEPS:  0.01\n","ITER:  148 \tRWD:  59.15 \tM_RWD:  161.96 \tLEN:  69 \tEPS:  0.01\n","ITER:  149 \tRWD:  181.65 \tM_RWD:  161.93 \tLEN:  172 \tEPS:  0.01\n","ITER:  150 \tRWD:  187.45 \tM_RWD:  162.16 \tLEN:  180 \tEPS:  0.01\n","ITER:  151 \tRWD:  176.7 \tM_RWD:  162.3 \tLEN:  2005 \tEPS:  0.01\n","ITER:  152 \tRWD:  183.45 \tM_RWD:  162.24 \tLEN:  183 \tEPS:  0.01\n","ITER:  153 \tRWD:  179.55 \tM_RWD:  163.65 \tLEN:  2005 \tEPS:  0.01\n","ITER:  154 \tRWD:  187.35 \tM_RWD:  163.64 \tLEN:  177 \tEPS:  0.01\n","ITER:  155 \tRWD:  180.75 \tM_RWD:  163.81 \tLEN:  187 \tEPS:  0.01\n","ITER:  156 \tRWD:  186.0 \tM_RWD:  163.85 \tLEN:  189 \tEPS:  0.01\n","ITER:  157 \tRWD:  167.55 \tM_RWD:  163.76 \tLEN:  154 \tEPS:  0.01\n","ITER:  158 \tRWD:  167.0 \tM_RWD:  163.77 \tLEN:  181 \tEPS:  0.01\n","ITER:  159 \tRWD:  166.4 \tM_RWD:  163.86 \tLEN:  156 \tEPS:  0.01\n","ITER:  160 \tRWD:  182.0 \tM_RWD:  163.81 \tLEN:  184 \tEPS:  0.01\n","ITER:  161 \tRWD:  183.15 \tM_RWD:  163.91 \tLEN:  2005 \tEPS:  0.01\n","ITER:  162 \tRWD:  175.9 \tM_RWD:  163.88 \tLEN:  185 \tEPS:  0.01\n","ITER:  163 \tRWD:  165.4 \tM_RWD:  164.97 \tLEN:  156 \tEPS:  0.01\n","ITER:  164 \tRWD:  188.2 \tM_RWD:  164.54 \tLEN:  175 \tEPS:  0.01\n","ITER:  165 \tRWD:  164.4 \tM_RWD:  164.46 \tLEN:  156 \tEPS:  0.01\n","ITER:  166 \tRWD:  164.15 \tM_RWD:  164.29 \tLEN:  159 \tEPS:  0.01\n","ITER:  167 \tRWD:  76.3 \tM_RWD:  163.38 \tLEN:  128 \tEPS:  0.01\n","ITER:  168 \tRWD:  55.65 \tM_RWD:  162.26 \tLEN:  63 \tEPS:  0.01\n","ITER:  169 \tRWD:  165.15 \tM_RWD:  162.12 \tLEN:  158 \tEPS:  0.01\n","ITER:  170 \tRWD:  180.2 \tM_RWD:  162.14 \tLEN:  2005 \tEPS:  0.01\n","ITER:  171 \tRWD:  126.8 \tM_RWD:  161.69 \tLEN:  161 \tEPS:  0.01\n","ITER:  172 \tRWD:  189.4 \tM_RWD:  161.82 \tLEN:  174 \tEPS:  0.01\n","ITER:  173 \tRWD:  185.15 \tM_RWD:  161.87 \tLEN:  180 \tEPS:  0.01\n","ITER:  174 \tRWD:  182.35 \tM_RWD:  161.95 \tLEN:  451 \tEPS:  0.01\n","ITER:  175 \tRWD:  164.55 \tM_RWD:  161.93 \tLEN:  167 \tEPS:  0.01\n","ITER:  176 \tRWD:  168.4 \tM_RWD:  161.81 \tLEN:  155 \tEPS:  0.01\n","ITER:  177 \tRWD:  163.75 \tM_RWD:  161.81 \tLEN:  155 \tEPS:  0.01\n","ITER:  178 \tRWD:  111.65 \tM_RWD:  161.05 \tLEN:  146 \tEPS:  0.01\n","ITER:  179 \tRWD:  181.95 \tM_RWD:  161.03 \tLEN:  2005 \tEPS:  0.01\n","ITER:  180 \tRWD:  127.9 \tM_RWD:  160.52 \tLEN:  125 \tEPS:  0.01\n","ITER:  181 \tRWD:  174.1 \tM_RWD:  160.7 \tLEN:  531 \tEPS:  0.01\n","ITER:  182 \tRWD:  181.1 \tM_RWD:  160.85 \tLEN:  165 \tEPS:  0.01\n","ITER:  183 \tRWD:  168.05 \tM_RWD:  160.8 \tLEN:  154 \tEPS:  0.01\n","ITER:  184 \tRWD:  181.35 \tM_RWD:  160.8 \tLEN:  2005 \tEPS:  0.01\n","ITER:  185 \tRWD:  188.7 \tM_RWD:  160.91 \tLEN:  173 \tEPS:  0.01\n","ITER:  186 \tRWD:  167.9 \tM_RWD:  160.87 \tLEN:  154 \tEPS:  0.01\n","ITER:  187 \tRWD:  58.65 \tM_RWD:  159.81 \tLEN:  68 \tEPS:  0.01\n","ITER:  188 \tRWD:  56.5 \tM_RWD:  158.56 \tLEN:  201 \tEPS:  0.01\n","ITER:  189 \tRWD:  60.4 \tM_RWD:  157.4 \tLEN:  68 \tEPS:  0.01\n","ITER:  190 \tRWD:  183.6 \tM_RWD:  157.55 \tLEN:  220 \tEPS:  0.01\n","ITER:  191 \tRWD:  58.4 \tM_RWD:  156.36 \tLEN:  68 \tEPS:  0.01\n","ITER:  192 \tRWD:  185.55 \tM_RWD:  156.52 \tLEN:  402 \tEPS:  0.01\n","ITER:  193 \tRWD:  185.35 \tM_RWD:  156.63 \tLEN:  206 \tEPS:  0.01\n","ITER:  194 \tRWD:  185.9 \tM_RWD:  157.09 \tLEN:  190 \tEPS:  0.01\n","ITER:  195 \tRWD:  76.15 \tM_RWD:  157.29 \tLEN:  172 \tEPS:  0.01\n","ITER:  196 \tRWD:  168.95 \tM_RWD:  158.42 \tLEN:  156 \tEPS:  0.01\n","ITER:  197 \tRWD:  187.35 \tM_RWD:  159.62 \tLEN:  173 \tEPS:  0.01\n","ITER:  198 \tRWD:  167.55 \tM_RWD:  159.48 \tLEN:  155 \tEPS:  0.01\n","ITER:  199 \tRWD:  186.2 \tM_RWD:  159.82 \tLEN:  229 \tEPS:  0.01\n","ITER:  200 \tRWD:  49.1 \tM_RWD:  158.47 \tLEN:  584 \tEPS:  0.01\n","ITER:  201 \tRWD:  169.0 \tM_RWD:  159.62 \tLEN:  166 \tEPS:  0.01\n","ITER:  202 \tRWD:  135.4 \tM_RWD:  159.12 \tLEN:  268 \tEPS:  0.01\n","ITER:  203 \tRWD:  128.35 \tM_RWD:  158.73 \tLEN:  124 \tEPS:  0.01\n","ITER:  204 \tRWD:  169.05 \tM_RWD:  158.69 \tLEN:  155 \tEPS:  0.01\n","ITER:  205 \tRWD:  127.25 \tM_RWD:  158.15 \tLEN:  129 \tEPS:  0.01\n","ITER:  206 \tRWD:  139.3 \tM_RWD:  157.74 \tLEN:  138 \tEPS:  0.01\n","ITER:  207 \tRWD:  165.5 \tM_RWD:  157.68 \tLEN:  154 \tEPS:  0.01\n","ITER:  208 \tRWD:  182.25 \tM_RWD:  158.52 \tLEN:  2005 \tEPS:  0.01\n","ITER:  209 \tRWD:  187.45 \tM_RWD:  158.58 \tLEN:  173 \tEPS:  0.01\n","ITER:  210 \tRWD:  163.4 \tM_RWD:  158.39 \tLEN:  166 \tEPS:  0.01\n","ITER:  211 \tRWD:  178.6 \tM_RWD:  158.45 \tLEN:  203 \tEPS:  0.01\n","ITER:  212 \tRWD:  187.45 \tM_RWD:  158.6 \tLEN:  185 \tEPS:  0.01\n","ITER:  213 \tRWD:  178.4 \tM_RWD:  158.65 \tLEN:  190 \tEPS:  0.01\n","ITER:  214 \tRWD:  179.0 \tM_RWD:  158.64 \tLEN:  198 \tEPS:  0.01\n","ITER:  215 \tRWD:  173.95 \tM_RWD:  158.76 \tLEN:  226 \tEPS:  0.01\n","ITER:  216 \tRWD:  59.15 \tM_RWD:  157.56 \tLEN:  68 \tEPS:  0.01\n","ITER:  217 \tRWD:  180.35 \tM_RWD:  157.58 \tLEN:  279 \tEPS:  0.01\n","ITER:  218 \tRWD:  178.9 \tM_RWD:  157.74 \tLEN:  196 \tEPS:  0.01\n","ITER:  219 \tRWD:  127.5 \tM_RWD:  156.75 \tLEN:  124 \tEPS:  0.01\n","ITER:  220 \tRWD:  173.15 \tM_RWD:  156.95 \tLEN:  378 \tEPS:  0.01\n","ITER:  221 \tRWD:  180.15 \tM_RWD:  156.91 \tLEN:  193 \tEPS:  0.01\n","ITER:  222 \tRWD:  165.25 \tM_RWD:  156.74 \tLEN:  181 \tEPS:  0.01\n","ITER:  223 \tRWD:  189.1 \tM_RWD:  156.95 \tLEN:  178 \tEPS:  0.01\n","ITER:  224 \tRWD:  176.95 \tM_RWD:  156.93 \tLEN:  296 \tEPS:  0.01\n","ITER:  225 \tRWD:  178.85 \tM_RWD:  157.19 \tLEN:  2005 \tEPS:  0.01\n","ITER:  226 \tRWD:  140.3 \tM_RWD:  156.73 \tLEN:  2005 \tEPS:  0.01\n","ITER:  227 \tRWD:  140.65 \tM_RWD:  156.32 \tLEN:  2005 \tEPS:  0.01\n","ITER:  228 \tRWD:  178.7 \tM_RWD:  158.03 \tLEN:  2005 \tEPS:  0.01\n","ITER:  229 \tRWD:  187.05 \tM_RWD:  158.0 \tLEN:  186 \tEPS:  0.01\n","ITER:  230 \tRWD:  180.3 \tM_RWD:  157.97 \tLEN:  2005 \tEPS:  0.01\n","ITER:  231 \tRWD:  188.8 \tM_RWD:  159.19 \tLEN:  181 \tEPS:  0.01\n","ITER:  232 \tRWD:  179.25 \tM_RWD:  159.18 \tLEN:  2005 \tEPS:  0.01\n","ITER:  233 \tRWD:  182.95 \tM_RWD:  159.37 \tLEN:  2005 \tEPS:  0.01\n","ITER:  234 \tRWD:  187.85 \tM_RWD:  159.43 \tLEN:  2005 \tEPS:  0.01\n","ITER:  235 \tRWD:  180.3 \tM_RWD:  159.34 \tLEN:  172 \tEPS:  0.01\n","ITER:  236 \tRWD:  179.95 \tM_RWD:  159.61 \tLEN:  2005 \tEPS:  0.01\n","ITER:  237 \tRWD:  179.75 \tM_RWD:  159.87 \tLEN:  2005 \tEPS:  0.01\n","ITER:  238 \tRWD:  181.6 \tM_RWD:  160.16 \tLEN:  2005 \tEPS:  0.01\n","ITER:  239 \tRWD:  187.5 \tM_RWD:  160.27 \tLEN:  191 \tEPS:  0.01\n","ITER:  240 \tRWD:  164.9 \tM_RWD:  160.09 \tLEN:  153 \tEPS:  0.01\n","ITER:  241 \tRWD:  156.8 \tM_RWD:  160.29 \tLEN:  534 \tEPS:  0.01\n","ITER:  242 \tRWD:  181.25 \tM_RWD:  160.79 \tLEN:  2005 \tEPS:  0.01\n","ITER:  243 \tRWD:  179.7 \tM_RWD:  160.9 \tLEN:  2005 \tEPS:  0.01\n","ITER:  244 \tRWD:  183.95 \tM_RWD:  161.11 \tLEN:  2005 \tEPS:  0.01\n","ITER:  245 \tRWD:  18.7 \tM_RWD:  159.76 \tLEN:  29 \tEPS:  0.01\n","ITER:  246 \tRWD:  139.5 \tM_RWD:  159.51 \tLEN:  128 \tEPS:  0.01\n","ITER:  247 \tRWD:  18.5 \tM_RWD:  157.88 \tLEN:  30 \tEPS:  0.01\n","ITER:  248 \tRWD:  102.9 \tM_RWD:  158.32 \tLEN:  101 \tEPS:  0.01\n","ITER:  249 \tRWD:  163.5 \tM_RWD:  158.14 \tLEN:  161 \tEPS:  0.01\n","ITER:  250 \tRWD:  128.7 \tM_RWD:  157.55 \tLEN:  126 \tEPS:  0.01\n","ITER:  251 \tRWD:  187.95 \tM_RWD:  157.66 \tLEN:  180 \tEPS:  0.01\n","ITER:  252 \tRWD:  188.4 \tM_RWD:  157.71 \tLEN:  175 \tEPS:  0.01\n","ITER:  253 \tRWD:  177.1 \tM_RWD:  157.69 \tLEN:  2005 \tEPS:  0.01\n","ITER:  254 \tRWD:  127.55 \tM_RWD:  157.09 \tLEN:  125 \tEPS:  0.01\n","ITER:  255 \tRWD:  186.85 \tM_RWD:  157.15 \tLEN:  220 \tEPS:  0.01\n","ITER:  256 \tRWD:  188.95 \tM_RWD:  157.18 \tLEN:  176 \tEPS:  0.01\n","ITER:  257 \tRWD:  18.5 \tM_RWD:  155.69 \tLEN:  33 \tEPS:  0.01\n","ITER:  258 \tRWD:  166.2 \tM_RWD:  155.68 \tLEN:  156 \tEPS:  0.01\n","ITER:  259 \tRWD:  186.75 \tM_RWD:  155.89 \tLEN:  2005 \tEPS:  0.01\n","ITER:  260 \tRWD:  181.0 \tM_RWD:  155.88 \tLEN:  2005 \tEPS:  0.01\n","ITER:  261 \tRWD:  181.1 \tM_RWD:  155.86 \tLEN:  165 \tEPS:  0.01\n","ITER:  262 \tRWD:  186.95 \tM_RWD:  155.97 \tLEN:  189 \tEPS:  0.01\n","ITER:  263 \tRWD:  183.5 \tM_RWD:  156.15 \tLEN:  2005 \tEPS:  0.01\n","ITER:  264 \tRWD:  130.2 \tM_RWD:  155.57 \tLEN:  143 \tEPS:  0.01\n","ITER:  265 \tRWD:  175.9 \tM_RWD:  155.68 \tLEN:  2005 \tEPS:  0.01\n","ITER:  266 \tRWD:  180.3 \tM_RWD:  155.84 \tLEN:  2005 \tEPS:  0.01\n","ITER:  267 \tRWD:  165.1 \tM_RWD:  156.73 \tLEN:  167 \tEPS:  0.01\n","ITER:  268 \tRWD:  180.5 \tM_RWD:  157.98 \tLEN:  2005 \tEPS:  0.01\n","ITER:  269 \tRWD:  138.7 \tM_RWD:  157.72 \tLEN:  129 \tEPS:  0.01\n","ITER:  270 \tRWD:  136.75 \tM_RWD:  157.28 \tLEN:  271 \tEPS:  0.01\n","ITER:  271 \tRWD:  184.65 \tM_RWD:  157.86 \tLEN:  2005 \tEPS:  0.01\n","ITER:  272 \tRWD:  59.65 \tM_RWD:  156.56 \tLEN:  69 \tEPS:  0.01\n","ITER:  273 \tRWD:  129.6 \tM_RWD:  156.01 \tLEN:  133 \tEPS:  0.01\n","ITER:  274 \tRWD:  187.55 \tM_RWD:  156.06 \tLEN:  185 \tEPS:  0.01\n","ITER:  275 \tRWD:  182.4 \tM_RWD:  156.24 \tLEN:  2005 \tEPS:  0.01\n","ITER:  276 \tRWD:  59.65 \tM_RWD:  155.15 \tLEN:  68 \tEPS:  0.01\n","ITER:  277 \tRWD:  181.95 \tM_RWD:  155.33 \tLEN:  2005 \tEPS:  0.01\n","ITER:  278 \tRWD:  127.7 \tM_RWD:  155.49 \tLEN:  132 \tEPS:  0.01\n","ITER:  279 \tRWD:  189.85 \tM_RWD:  155.57 \tLEN:  176 \tEPS:  0.01\n","ITER:  280 \tRWD:  183.3 \tM_RWD:  156.12 \tLEN:  2005 \tEPS:  0.01\n","ITER:  281 \tRWD:  186.15 \tM_RWD:  156.25 \tLEN:  2005 \tEPS:  0.01\n","ITER:  282 \tRWD:  182.15 \tM_RWD:  156.26 \tLEN:  2005 \tEPS:  0.01\n","ITER:  283 \tRWD:  184.65 \tM_RWD:  156.42 \tLEN:  2005 \tEPS:  0.01\n","ITER:  284 \tRWD:  54.45 \tM_RWD:  155.15 \tLEN:  60 \tEPS:  0.01\n","ITER:  285 \tRWD:  187.9 \tM_RWD:  155.14 \tLEN:  2005 \tEPS:  0.01\n","ITER:  286 \tRWD:  186.7 \tM_RWD:  155.33 \tLEN:  173 \tEPS:  0.01\n","ITER:  287 \tRWD:  189.7 \tM_RWD:  156.64 \tLEN:  2005 \tEPS:  0.01\n","ITER:  288 \tRWD:  180.25 \tM_RWD:  157.88 \tLEN:  2005 \tEPS:  0.01\n","ITER:  289 \tRWD:  184.4 \tM_RWD:  159.12 \tLEN:  2005 \tEPS:  0.01\n","ITER:  290 \tRWD:  179.7 \tM_RWD:  159.08 \tLEN:  2005 \tEPS:  0.01\n","ITER:  291 \tRWD:  183.9 \tM_RWD:  160.34 \tLEN:  2005 \tEPS:  0.01\n","ITER:  292 \tRWD:  181.6 \tM_RWD:  160.3 \tLEN:  2005 \tEPS:  0.01\n","ITER:  293 \tRWD:  187.85 \tM_RWD:  160.32 \tLEN:  2005 \tEPS:  0.01\n","ITER:  294 \tRWD:  183.85 \tM_RWD:  160.3 \tLEN:  2005 \tEPS:  0.01\n","ITER:  295 \tRWD:  183.45 \tM_RWD:  161.37 \tLEN:  2005 \tEPS:  0.01\n","ITER:  296 \tRWD:  164.05 \tM_RWD:  161.33 \tLEN:  178 \tEPS:  0.01\n","ITER:  297 \tRWD:  181.55 \tM_RWD:  161.27 \tLEN:  2005 \tEPS:  0.01\n","ITER:  298 \tRWD:  99.85 \tM_RWD:  160.59 \tLEN:  110 \tEPS:  0.01\n","ITER:  299 \tRWD:  153.7 \tM_RWD:  160.27 \tLEN:  152 \tEPS:  0.01\n","ITER:  300 \tRWD:  18.8 \tM_RWD:  159.96 \tLEN:  29 \tEPS:  0.01\n","ITER:  301 \tRWD:  60.65 \tM_RWD:  158.88 \tLEN:  69 \tEPS:  0.01\n","ITER:  302 \tRWD:  165.25 \tM_RWD:  159.18 \tLEN:  158 \tEPS:  0.01\n","ITER:  303 \tRWD:  163.85 \tM_RWD:  159.53 \tLEN:  158 \tEPS:  0.01\n","ITER:  304 \tRWD:  165.55 \tM_RWD:  159.5 \tLEN:  163 \tEPS:  0.01\n","ITER:  305 \tRWD:  164.1 \tM_RWD:  159.87 \tLEN:  169 \tEPS:  0.01\n","ITER:  306 \tRWD:  99.7 \tM_RWD:  159.47 \tLEN:  105 \tEPS:  0.01\n","ITER:  307 \tRWD:  164.8 \tM_RWD:  159.46 \tLEN:  186 \tEPS:  0.01\n","ITER:  308 \tRWD:  99.9 \tM_RWD:  158.64 \tLEN:  104 \tEPS:  0.01\n","ITER:  309 \tRWD:  180.85 \tM_RWD:  158.57 \tLEN:  2005 \tEPS:  0.01\n","ITER:  310 \tRWD:  164.65 \tM_RWD:  158.59 \tLEN:  225 \tEPS:  0.01\n","ITER:  311 \tRWD:  55.35 \tM_RWD:  157.35 \tLEN:  58 \tEPS:  0.01\n","ITER:  312 \tRWD:  190.2 \tM_RWD:  157.38 \tLEN:  203 \tEPS:  0.01\n","ITER:  313 \tRWD:  99.4 \tM_RWD:  156.59 \tLEN:  125 \tEPS:  0.01\n","ITER:  314 \tRWD:  187.0 \tM_RWD:  156.67 \tLEN:  2005 \tEPS:  0.01\n","ITER:  315 \tRWD:  184.7 \tM_RWD:  156.78 \tLEN:  2005 \tEPS:  0.01\n","ITER:  316 \tRWD:  184.45 \tM_RWD:  158.03 \tLEN:  2005 \tEPS:  0.01\n","ITER:  317 \tRWD:  182.6 \tM_RWD:  158.05 \tLEN:  2005 \tEPS:  0.01\n","ITER:  318 \tRWD:  99.7 \tM_RWD:  157.26 \tLEN:  108 \tEPS:  0.01\n","ITER:  319 \tRWD:  99.75 \tM_RWD:  156.98 \tLEN:  101 \tEPS:  0.01\n","ITER:  320 \tRWD:  181.9 \tM_RWD:  157.07 \tLEN:  2005 \tEPS:  0.01\n","ITER:  321 \tRWD:  163.75 \tM_RWD:  156.91 \tLEN:  161 \tEPS:  0.01\n","ITER:  322 \tRWD:  76.8 \tM_RWD:  156.02 \tLEN:  126 \tEPS:  0.01\n","ITER:  323 \tRWD:  138.8 \tM_RWD:  155.52 \tLEN:  135 \tEPS:  0.01\n","ITER:  324 \tRWD:  181.3 \tM_RWD:  155.56 \tLEN:  2005 \tEPS:  0.01\n","ITER:  325 \tRWD:  128.0 \tM_RWD:  155.06 \tLEN:  122 \tEPS:  0.01\n","ITER:  326 \tRWD:  180.05 \tM_RWD:  155.45 \tLEN:  2005 \tEPS:  0.01\n","ITER:  327 \tRWD:  163.75 \tM_RWD:  155.68 \tLEN:  175 \tEPS:  0.01\n","ITER:  328 \tRWD:  176.15 \tM_RWD:  155.66 \tLEN:  2005 \tEPS:  0.01\n","ITER:  329 \tRWD:  181.4 \tM_RWD:  155.6 \tLEN:  2005 \tEPS:  0.01\n","ITER:  330 \tRWD:  17.95 \tM_RWD:  153.98 \tLEN:  31 \tEPS:  0.01\n","ITER:  331 \tRWD:  166.85 \tM_RWD:  153.76 \tLEN:  166 \tEPS:  0.01\n","ITER:  332 \tRWD:  187.55 \tM_RWD:  153.84 \tLEN:  2005 \tEPS:  0.01\n","ITER:  333 \tRWD:  163.0 \tM_RWD:  153.64 \tLEN:  155 \tEPS:  0.01\n","ITER:  334 \tRWD:  183.45 \tM_RWD:  153.6 \tLEN:  2005 \tEPS:  0.01\n","ITER:  335 \tRWD:  184.35 \tM_RWD:  153.64 \tLEN:  2005 \tEPS:  0.01\n","ITER:  336 \tRWD:  188.2 \tM_RWD:  153.72 \tLEN:  213 \tEPS:  0.01\n","ITER:  337 \tRWD:  163.75 \tM_RWD:  153.56 \tLEN:  183 \tEPS:  0.01\n","ITER:  338 \tRWD:  151.0 \tM_RWD:  153.26 \tLEN:  226 \tEPS:  0.01\n","ITER:  339 \tRWD:  184.5 \tM_RWD:  153.23 \tLEN:  2005 \tEPS:  0.01\n","ITER:  340 \tRWD:  184.0 \tM_RWD:  153.42 \tLEN:  2005 \tEPS:  0.01\n","ITER:  341 \tRWD:  163.1 \tM_RWD:  153.48 \tLEN:  157 \tEPS:  0.01\n","ITER:  342 \tRWD:  183.3 \tM_RWD:  153.5 \tLEN:  2005 \tEPS:  0.01\n","ITER:  343 \tRWD:  128.25 \tM_RWD:  152.99 \tLEN:  130 \tEPS:  0.01\n","ITER:  344 \tRWD:  183.8 \tM_RWD:  152.98 \tLEN:  2005 \tEPS:  0.01\n","ITER:  345 \tRWD:  165.5 \tM_RWD:  154.45 \tLEN:  158 \tEPS:  0.01\n","ITER:  346 \tRWD:  183.0 \tM_RWD:  154.89 \tLEN:  2005 \tEPS:  0.01\n","ITER:  347 \tRWD:  181.8 \tM_RWD:  156.52 \tLEN:  2005 \tEPS:  0.01\n","ITER:  348 \tRWD:  137.2 \tM_RWD:  156.86 \tLEN:  139 \tEPS:  0.01\n","ITER:  349 \tRWD:  191.0 \tM_RWD:  157.14 \tLEN:  199 \tEPS:  0.01\n","ITER:  350 \tRWD:  164.4 \tM_RWD:  157.5 \tLEN:  154 \tEPS:  0.01\n","ITER:  351 \tRWD:  187.6 \tM_RWD:  157.49 \tLEN:  222 \tEPS:  0.01\n","ITER:  352 \tRWD:  181.55 \tM_RWD:  157.42 \tLEN:  2005 \tEPS:  0.01\n","ITER:  353 \tRWD:  182.65 \tM_RWD:  157.48 \tLEN:  2005 \tEPS:  0.01\n","ITER:  354 \tRWD:  181.15 \tM_RWD:  158.01 \tLEN:  191 \tEPS:  0.01\n","ITER:  355 \tRWD:  164.4 \tM_RWD:  157.79 \tLEN:  163 \tEPS:  0.01\n","ITER:  356 \tRWD:  175.65 \tM_RWD:  157.66 \tLEN:  2005 \tEPS:  0.01\n","ITER:  357 \tRWD:  188.0 \tM_RWD:  159.35 \tLEN:  170 \tEPS:  0.01\n","ITER:  358 \tRWD:  183.0 \tM_RWD:  159.52 \tLEN:  2005 \tEPS:  0.01\n","ITER:  359 \tRWD:  163.2 \tM_RWD:  159.28 \tLEN:  157 \tEPS:  0.01\n","ITER:  360 \tRWD:  180.65 \tM_RWD:  159.28 \tLEN:  2005 \tEPS:  0.01\n","ITER:  361 \tRWD:  75.15 \tM_RWD:  158.22 \tLEN:  149 \tEPS:  0.01\n","ITER:  362 \tRWD:  76.8 \tM_RWD:  157.12 \tLEN:  126 \tEPS:  0.01\n","ITER:  363 \tRWD:  98.2 \tM_RWD:  156.27 \tLEN:  206 \tEPS:  0.01\n","ITER:  364 \tRWD:  73.0 \tM_RWD:  155.7 \tLEN:  318 \tEPS:  0.01\n","ITER:  365 \tRWD:  183.0 \tM_RWD:  155.77 \tLEN:  165 \tEPS:  0.01\n","ITER:  366 \tRWD:  187.65 \tM_RWD:  155.84 \tLEN:  179 \tEPS:  0.01\n","ITER:  367 \tRWD:  76.05 \tM_RWD:  154.95 \tLEN:  126 \tEPS:  0.01\n","ITER:  368 \tRWD:  188.1 \tM_RWD:  155.03 \tLEN:  185 \tEPS:  0.01\n","ITER:  369 \tRWD:  111.05 \tM_RWD:  154.75 \tLEN:  117 \tEPS:  0.01\n","ITER:  370 \tRWD:  182.65 \tM_RWD:  155.21 \tLEN:  164 \tEPS:  0.01\n","ITER:  371 \tRWD:  186.8 \tM_RWD:  155.23 \tLEN:  184 \tEPS:  0.01\n","ITER:  372 \tRWD:  164.4 \tM_RWD:  156.28 \tLEN:  157 \tEPS:  0.01\n","ITER:  373 \tRWD:  184.95 \tM_RWD:  156.83 \tLEN:  2005 \tEPS:  0.01\n","ITER:  374 \tRWD:  187.3 \tM_RWD:  156.83 \tLEN:  198 \tEPS:  0.01\n","ITER:  375 \tRWD:  153.1 \tM_RWD:  156.53 \tLEN:  174 \tEPS:  0.01\n","ITER:  376 \tRWD:  204.85 \tM_RWD:  157.99 \tLEN:  1583 \tEPS:  0.01\n","ITER:  377 \tRWD:  99.4 \tM_RWD:  157.16 \tLEN:  101 \tEPS:  0.01\n","ITER:  378 \tRWD:  101.0 \tM_RWD:  156.89 \tLEN:  104 \tEPS:  0.01\n","ITER:  379 \tRWD:  190.7 \tM_RWD:  156.9 \tLEN:  181 \tEPS:  0.01\n","ITER:  380 \tRWD:  186.7 \tM_RWD:  156.94 \tLEN:  181 \tEPS:  0.01\n","ITER:  381 \tRWD:  152.4 \tM_RWD:  156.6 \tLEN:  178 \tEPS:  0.01\n","ITER:  382 \tRWD:  188.75 \tM_RWD:  156.67 \tLEN:  186 \tEPS:  0.01\n","ITER:  383 \tRWD:  183.6 \tM_RWD:  156.65 \tLEN:  2005 \tEPS:  0.01\n","ITER:  384 \tRWD:  181.4 \tM_RWD:  157.92 \tLEN:  169 \tEPS:  0.01\n","ITER:  385 \tRWD:  163.65 \tM_RWD:  157.68 \tLEN:  163 \tEPS:  0.01\n","ITER:  386 \tRWD:  184.25 \tM_RWD:  157.66 \tLEN:  2005 \tEPS:  0.01\n","ITER:  387 \tRWD:  185.7 \tM_RWD:  157.62 \tLEN:  2005 \tEPS:  0.01\n","ITER:  388 \tRWD:  165.2 \tM_RWD:  157.47 \tLEN:  152 \tEPS:  0.01\n","ITER:  389 \tRWD:  186.65 \tM_RWD:  157.49 \tLEN:  2005 \tEPS:  0.01\n","ITER:  390 \tRWD:  177.95 \tM_RWD:  157.47 \tLEN:  2005 \tEPS:  0.01\n","ITER:  391 \tRWD:  184.05 \tM_RWD:  157.47 \tLEN:  2005 \tEPS:  0.01\n","ITER:  392 \tRWD:  163.95 \tM_RWD:  157.3 \tLEN:  161 \tEPS:  0.01\n","ITER:  393 \tRWD:  247.8 \tM_RWD:  157.9 \tLEN:  2005 \tEPS:  0.01\n","ITER:  394 \tRWD:  201.3 \tM_RWD:  158.07 \tLEN:  1763 \tEPS:  0.01\n","ITER:  395 \tRWD:  186.4 \tM_RWD:  158.1 \tLEN:  189 \tEPS:  0.01\n","ITER:  396 \tRWD:  152.5 \tM_RWD:  157.98 \tLEN:  147 \tEPS:  0.01\n","ITER:  397 \tRWD:  172.95 \tM_RWD:  157.9 \tLEN:  2005 \tEPS:  0.01\n","ITER:  398 \tRWD:  208.95 \tM_RWD:  158.99 \tLEN:  1360 \tEPS:  0.01\n","ITER:  399 \tRWD:  153.15 \tM_RWD:  158.98 \tLEN:  145 \tEPS:  0.01\n","ITER:  400 \tRWD:  190.1 \tM_RWD:  160.7 \tLEN:  219 \tEPS:  0.01\n","ITER:  401 \tRWD:  218.9 \tM_RWD:  162.28 \tLEN:  760 \tEPS:  0.01\n","ITER:  402 \tRWD:  184.4 \tM_RWD:  162.47 \tLEN:  347 \tEPS:  0.01\n","ITER:  403 \tRWD:  201.3 \tM_RWD:  162.85 \tLEN:  1743 \tEPS:  0.01\n","ITER:  404 \tRWD:  183.8 \tM_RWD:  163.03 \tLEN:  2005 \tEPS:  0.01\n","ITER:  405 \tRWD:  190.5 \tM_RWD:  163.29 \tLEN:  173 \tEPS:  0.01\n","\n"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-20-e750ca7c4867>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;31m# e-GREEDY ACTION\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobservation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mobservation_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mtotal_reward\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-10-9b350943b385>\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0mobservation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m         \u001b[0mreward\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'score'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_current_score\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m40.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_current_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'score'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/gym/core.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    259\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 261\u001b[0;31m         \u001b[0mobservation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    262\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobservation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobservation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-10-9b350943b385>\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mframe\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframe_skip\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m             \u001b[0mobservation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m             \u001b[0mtotal_reward\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/gym/core.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    260\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0mobservation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobservation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobservation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mobservation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobservation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-10-9b350943b385>\u001b[0m in \u001b[0;36mobservation\u001b[0;34m(self, observation)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mobservation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobservation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mtemp_frame\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobservation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_RGB2GRAY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mtemp_frame\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp_frame\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew_observation_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterpolation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mINTER_AREA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mnew_observation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp_frame\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew_observation_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"cb8lXFP74Hx1","executionInfo":{"elapsed":1560,"status":"ok","timestamp":1597673357093,"user":{"displayName":"Nimish Santosh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhsAwxKElAXr8GplXnBLHw_yAJ2JTflUac_fPVFCQ=s64","userId":"01747774516062944150"},"user_tz":-330},"outputId":"462ca322-3ce6-4c53-f017-43790e9ce314","colab":{"base_uri":"https://localhost:8080/","height":52}},"source":["# ## MANUAL SAVE\n","# agent.save_models()\n","\n","# train_metadata = {\n","#     'episode_n': len(mean_rewards),\n","#     'best_reward': best_reward,\n","#     'mean_rewards': mean_rewards,\n","#     'episode_rewards': episode_rewards, \n","#     'episode_lengths': episode_lengths,\n","#     'episode_epsilons': episode_epsilons\n","# }\n","# T.save(train_metadata, (ROOT+\"/train_metadata.pkl\"))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[INFO] Saving model\n","[INFO] Saving model\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"jgHMCs-EfuWB"},"source":["## **Testing**"]},{"cell_type":"code","metadata":{"tags":[],"id":"s5WBsmLWfuWC","outputId":"f8beb56e-6e4c-419f-9f8c-653b63e3c33d"},"source":["env_name = 'SuperMarioBros-1-4-v0'\n","env = make_env(env_name)\n","ROOT = './weights'\n","\n","agent = DuelingDDQNAgent(observation_shape=env.observation_space.shape,\n","                         n_actions=env.action_space.n,\n","                         lr=1e-4,\n","                         gamma=0.99,\n","                         epsilon=1.0,\n","                         epsilon_min=0.01,\n","                         epsilon_decay=1e-6,\n","                         mem_size=1,\n","                         batch_size=1,\n","                         Q_TARGET_replace_interval=1,\n","                         initial_exploration_steps = 1,\n","                         algo_name='DuelingDDQN',\n","                         env_name=env_name,\n","                         model_dir=ROOT)\n","\n","agent.load_models(cpu=True)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[INFO] Loading model\n","[INFO] Loading model\n"],"name":"stdout"},{"output_type":"stream","text":["<__array_function__ internals>:5: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"tags":[],"id":"L2T-AySDfuWJ","outputId":"512424c3-c64c-49c6-84d8-10701ced3bc8"},"source":["train_metadata = T.load((ROOT+\"/train_metadata-1-4.pkl\"))\n","print(train_metadata.keys())\n","print(\"ITER:\\t\",train_metadata['episode_n'])\n","print(\"BEST:\\t\",train_metadata['best_reward'])\n","\n","plt.plot(train_metadata['mean_rewards'])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["dict_keys(['episode_n', 'best_reward', 'mean_rewards', 'episode_rewards', 'episode_lengths', 'episode_epsilons'])\n","ITER:\t 3545\n","BEST:\t 149.5049999999998\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["[<matplotlib.lines.Line2D at 0x131e07640>]"]},"metadata":{"tags":[]},"execution_count":12},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAXcAAAD4CAYAAAAXUaZHAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/d3fzzAAAACXBIWXMAAAsTAAALEwEAmpwYAAAt10lEQVR4nO3dd3yV5fn48c+Vk00CIRAgECBhi8p2IogiQ5CKW6stdZQ62q/VVgtWqXXy9eds/WprnbWOurXFwXCjgmHvJQECIQQDIZCd3L8/znNOzskZGScnZ+R6v16+8jz3M3LlMVy5z/3cQ4wxKKWUii4xoQ5AKaVU69PkrpRSUUiTu1JKRSFN7kopFYU0uSulVBSKDXUAAF27djXZ2dmhDkMppSLKihUrDhpjMrwdC4vknp2dTW5ubqjDUEqpiCIiu3wd02YZpZSKQprclVIqCmlyV0qpKKTJXSmlopAmd6WUikKa3JVSKgppcldKqSikyV0ppULkhaU7WbC2ICj31uSulFLNsP3AUQD2Hi5n8/4jAd3rhaV5LNq4vzXC8hAWI1SVUioSLNlUyLUv5XLJ6CzeXJEPwAe/HsvAbqnE2YRFGwsZk51ORmpCo/eqqzPsLi5j3MCuQYlVk7tSSjXRjiJ7rd2R2MFek//Jk0vplBRHSXk1OV078NnvJzR6r9LKGgBSEoKThrVZRimlmihGxKNswz5700xJeTUAOw8ea9K98g+VATCgW0orRedOk7tSqt1atLGQN3P3NPl88ZLcF20sbNH3vvLZZQBs2V/aousbo8ldKdVu7D1cztLtB537v/xnLre9tTage/ZMS/Qo+2zzgUavO1xmr+n37dohoO/viyZ3pVS7cdFT33Dls8v4fEvjybehHUVH2Xe43KO8vLrOo+zZr39o9H5Tj+8BwFWn9Gl2LE2hyV0p1W7sP1IBwC9e+N6t/EhFdaPXTnzkC577eqdH+eYCz+6QS7f/yLur8j3KHUrKq/l4w35sMeK1qac1aHJXSrV7N/5rZbOv+cPUIQBU1njW3AEe/mSr13JjDPf9dyMAtXWm2d+3qTS5K6XavTX5h5t9zSVjspp03pu5e3hxaX2N/4M1+9y6UgaLJnelVLtQ51JL7t4xwa2XyrQTMv1e662GnRRnI97mnkIvP6m3x3m3vbWWu/+z0bm/tTA4vWMaajS5i8jzInJARNZ7OfZ7ETEi0tWlbK6IbBeRLSIypbUDVkqplnBtPslITWDK41869w+VVfm9trRBm/yvxvcjOd5GQpx7Cu2UHOfc3uvl5SvA+r2BTVnQVE2pub8ITG1YKCK9gUnAbpeyocDlwPHWNU+JiK1VIlVKqQCcfP9i53ZFgx4uCxvpq55/yD1Rz512HCJCYpx7enMd5DQ0s6PXe32xtahJ8Qaq0eRujPkSKPZy6DHgdsD188r5wOvGmEpjzE5gO3ByawSqlFKBcAz3h/rJv1yt3H3I57VFRysBGJbViVevO8VZnhBrT6EXj85iUPcUrnTp1tiw//unmwt5+ds8t7LHLxvR5Pibq0WTGojIT4C9xpg1Dbrx9AK+c9nPt8q83WM2MBugT5/g9PNUSimAyppar+W3TRnM//tkCwDHXJJ/Qx+s3gfA//10FL3Tk53lthh7/svukszDlwx3u2bxpgNu7fzXvJjrcd8Zw3s28Sdovma/UBWRZOCPwDxvh72Uee3rY4x5xhgzxhgzJiMjo7lhKKVUkxWVVnotT4qzMX2Y/WVqbIzvdPjuqr0AbokdwFjZLSm+vp6c5tLu/p+1+/zG5fjjEAwt6S3TH8gB1ohIHpAFrBSRHthr6q6vi7MA/z+dUkoF2X99LIjx1bYirj0jB/Bdu/enzsruSS5t71/8/izn9o6ipk0iFgzNTu7GmHXGmG7GmGxjTDb2hD7KGLMf+AC4XEQSRCQHGAgsb9WIlVJh4UhFNSVljY/sDAfvW80q04dl8slvxzvLu3dMJDHWnpgbvmR1MKbxgUZJ8fWp1LXHTHmV76aeV1za7oOhKV0hXwO+BQaLSL6IXOvrXGPMBuANYCPwMXCTMab5fw6VUmFv2N0LGX7PwlCH0STx1ovPJy4bweAeqc7y354ziESrO6OvmrujC+VAL1PzxlrNKkkNes08cMGJAKzec9jrPV++9mTGDgjOIh0OTektc4UxJtMYE2eMyTLGPNfgeLYx5qDL/v3GmP7GmMHGmI+CEbRSSjVHgi2G7h0TiLUGHfXLsM/E2LlDHAlWYl6+07NT4Bu5e9hTbJ93/adeJvhy3K9hl8iZI+0vSht2oXQYNzD47xl1hKpSyq+dB4+RPWcBK3bVdxVsSlNFuPhqWxHL84opPFL/UvX1X57Kc7PGkBBrc/YCeWXZbrfrikoruf2ttVzxD/u86w1r51Bfc0+Od+94mBRno0O8jYKSCo9rgtlDxpUmd6WUX9/ssH8wd13Uoqwqclpbv8/z7L/erWMiE4/rDkDXFPt6p5md3Pulb7Jmezxo9XFPivdM7o7eLo5mHwcRoauPdVTvO/+E5oTfYprclVJ+Odb4POrSD7y0wveLwnCz60f/PVbiY2Po2yWZk3PS3cp//rx7XxDHHwFXjpq7t7lndv1Y5tx++Vr7WM6px/dwe+EaTJrclVJ+OdqTXZO76/znVT6mvA0HdXXG2VOm4SRfrpLjYzlW6f/TiLeFrK+xulFmd0n2OOZq3MAM/v6z0Tx0ybDGQm41mtyVUn45aqVlLsnvx6P1E2099fn2No+pqV5ZXt+OnnvXOT7PS0mw+R2hCt6bZc4f0Yu8+dPp4qVW39CU43vQMbFtau2gyV0p1QhHm/PyvGKy5yzg3VX5bsvNPb54W6hCa9Rd79VPZpvqpebt0CEhlmMufdK9vTB29IdvqobNPG1Nk7tSyq9/fOW+Hugt/17D795cE6Jomqd7x/oatb/l7DrEx7I2v4S576wDvA9oSoxvXrqsC+IqS02hyV0p5dewrLRQh9BiM0fa5y18btYYv+c55mV/zWrGOeqliaa5TSqOqQmmn+h/IZBg0eSulPLL1oQFnMP1pWpdnSExLsbZ7dGXd1budbumzMu0AQ0HKjWm1qq4Xz02u1nXtRZN7kopv8qrffciceT9QXd+FPJmCG8qquuanZT73fFhq3T1dLTbx/rppRNMmtyVUj4t3LCfRX5WKXLMoQJQ3MhSdaHw2vLdHG7C5GaXNljs2rE4x4UjvS5H0SSOZpxkL71s2oImd6WUT7NfXgHAiN5pLLplvNuxRy4ZTmpifQ+U/V6G2odaTRM/Tbj+kQL4lfVzO5pzGo5AbYqHLxnOn2YM9TrhWFvQ5K6UalRRaSUDu6fyxW0TnGXTTsx0G9hzoDT8kntTNWw6cbxDcPzxOqMFMzj26JTI1WNz/PbSCaYWLbOnlGpf9lr92vt26cCLV59ESXk1SfG2BjV376sdhdoVJzdtGc+8+dPJnrPArWz8oAw+/u04+qT7H4EajrTmrpRyKiqtZPHGQlbscp/+1nV90AmDu3H+CHtbdHqH+n7kry7f5ZwTffuBo3y62XdbfVuosF4EZ3VOCug+Q3p09Jj1MRJocldKOV349FKu+2cuFz39LQs37HeWXzTK+4vFvi412vV7jzD4zo9ZufsQ5zz6hdcFoduSYzoBb3PC+LLjgWnBCqfNaXJXSgHw2KKt7Cmun1bgMZdpBXy1G8d4WeD5wqe+cW43Nl9LMH24zr5uanN6q7guWB2q/umtRZO7UgqAJ5a4zxHjWIEoEJv3Hwn4Hi111/sbgObV3F15m8Y3kmhyV0oBcFJ2Z7f9yUPt3QDvnel/cYl55w31eWzNnpLAAwuQzcunC3/uPf94oB0kdxF5XkQOiMh6l7L/JyKbRWStiLwrImkux+aKyHYR2SIiU4IUt1KqlW3ZX+q2/84q+5D8tCT/c6pcc0YOs8f383rsnv9u5LqX2rbtvbq2juutfurgfZ4Yf849MZNB3VO4bpz3nylSNKXm/iIwtUHZIuAEY8wwYCswF0BEhgKXA8db1zwlIqEZnqWUapYj1pD7N351mlt5U9qs75h2nM9jizcVtumaq++u3MvHLi+DL2jmKNOuKQksvOVMcrp2aO3Q2lSjyd0Y8yVQ3KBsoTHG8efwO8Axdvd84HVjTKUxZiewHTi5FeNVSgXBuvz65pOG85B7W6TCmy9vO8vnsebWnlvKGMPtb691KwvVIKJQa40292uAj6ztXsAel2P5VplSqo01dTqAH49WMuPJr30eb2of7z5dkvndpEHO/UHd64fdF5U2bYBTTW0d3/3wY5PO9Wbd3tC38YeLgJK7iPwRqAFecRR5Oc3r5zERmS0iuSKSW1RUFEgYSqkG1uw5zKkPLuGN3D2Nnru18KhH2e1TBzu3k5oxq+JvJg5k54PTyJs/nU4ubfU3vrLSub10+0Fed1n+ztX9H27i8me+Y2thqdfjjWn4EnT+hSf6ODP6tTi5i8gs4DzgSlPfoJYP9HY5LQvY5+16Y8wzxpgxxpgxGRkZLQ1DKeXFzoPHAPh628FGz62pq5+L/apT7UP1XReT7tExsVnf29EM0s3lus37S6mrM+woOsqVzy5jjrXiUUMvLM0DWt6ME9OgCebsId1adJ9o0KLkLiJTgT8APzHGuHaG/QC4XEQSRCQHGAgsDzxMpVRzOGYxbMoiGq613ftm2mu6jppz7/QkOiW3bFHnP80Y6vYyc+HGQiY+8oVz399L1kovy9w1RVVt/XXPzRrj9gemvWlKV8jXgG+BwSKSLyLXAk8CqcAiEVktIn8DMMZsAN4ANgIfAzcZY3zP9K+UCopqK8k55nrxxzEHy6vXneIsu+aMHLqmxPP29ae3OIZuqYk84jInzfX/WuF2fEeRe3NQbl59v40r/vGd2yLcTeX4WR69dHijqy9Fu6b0lrnCGJNpjIkzxmQZY54zxgwwxvQ2xoyw/rve5fz7jTH9jTGDjTEf+bu3Uio4bn59NQCVjdTca+sMGwsctfT6eWKG9OhI7p2TAq75xsQIW+5r2JPabndxGfsOlztHwv7tC/eFuGe/nNvsLpSOha0HdU9tQbTRRUeoKhXFGmuWeXTRFv5iTTvQMy2w2RN9SYj1/kL2qc92cPr8Txn30GcAnNirk9vx9XuPkDP3wyYl+De+30P2nAUctlaDSozT1KZPQKko45oMG6u5v7eqvr9Dc4fpByp31yG3/f1HyungpU+9azu6Lw8v3ALAJxvs0wz7+oPSnmhyVyqKlFZU8/r39d0fjfeeyAC8/N0u5yIcbWlE7zS3bpIOy3cW06tzkscgqvIq/+8NjlXWcMDqR794k5XcteauyV2paHLi3QuZ69LNcP3eI3y740f2FJexqaB+hsbVew5z13vrvd0i6N67aSwl5e6LVmfPWcCOomNsLTzKv649xe1YYwtcv7/as7d1XIymNn0CSkUpR3fIK/7xHeMe+oxzn/jKeWzm/y11O7d3enDa2x0cM0w2ZkiPVI/FqJ/+fIffazokeDbBpLWw+2Y00eSuVJRqSh93h0cvHRG8QICnrhzVpPNmWv3iv5s7ka9ut89Vc8h6SXr9yyt4d1W+xzXeBjy11/lkXGlyVyoKPPvVDx6LO3vj6Afu6p0bT+ek7HQvZ7eeWJt7qll863iv553evwsAPTol0js9mWFZnaiuraPwSAUfb9jPLf9e43FNaYV7cv/1WQNaKerIpsldqShw34JNHmV//9loj7LiY1W8smyXW9nxPTsGLS5f0pLjvZYPy0pz20+MtVFRXce9/93oLHOdhKyuzjD/o81u11wyJgsFkbekt1KqSRr2Gwd7LfeP77q/SG2rboMXj85ieO80AFIT61PP5nunev1EAbA8r9ij7OvtRVww0p7A//GV+8Cn0/t3oW+XyJ6HvbVoclcqwh2pcO9NMqJ3Go9fNoKeaUm8c+PpbgtWT3n8y7YOz+lhl6kIEmJt3DZlMP0zOpAYZyOxGTNPrtx12Jncn/x0u7P849+OI6tzsq/L2h1N7kpFuLs/2OC2/6vx/ci2VhEa0aCZw9Xp/btwxcl9ghmaXze1sG385e92sWrPIcqraim1Xqae0KsjQ3q0ffNSONM2d6Ui3IK1BW77rtMIxMQIf5rhfQHrF64+iRnDewY1tkC9fUP9kn+n9qt/6bt+7xF2FB1z7p85SKcNb0iTu1IRLqFBv/AOCe4fyK8em0Pe/Olergv/Ifqj+9Yn9Dib73TlaKZR9TS5KxXh+nbp4FZzzUhJCGE0wbM23/cSegO6pfg81l5pclcqwpVWVLvN1dLY4hrJ8TZeuPqkYIfVamad1heAkvJqxg3sGuJoIocmd6Ui3LGqWq9D8H3ZeM9UzhocOcvP3WItup0QG8PLLvPOXDiql69LFNpbRqmIV15VS1JcLE9fOYqURN//pG+fOpgNe4/4PB6uHG3tDWcUePTSESzdfpALR2l7uzea3JWKYMYYjlXVkBxv49wTM/2ee+OEyByWnxxv49IxWVx2Um8A7px+HCP7pAGw7I5zQhhZeNPkrlQEq6ypwxhI8rLIRbQQER66uH4A1HXj+oUwmsihbe5KRbCN1hztSc0Y4anah0aTu4g8LyIHRGS9S1m6iCwSkW3W184ux+aKyHYR2SIiU4IVuFLt3WvLdzunFnBMi6uUQ1Nq7i8CDZcvnwMsMcYMBJZY+4jIUOBy4HjrmqdERKsUSrWysqoatxWXWjqUX0WvRpO7MeZLoOHUbOcDL1nbLwEzXcpfN8ZUGmN2AtuBk1snVKWUw77DFW77zZl4S7UPLW1z726MKQCwvjo6zfYC9ricl2+VeRCR2SKSKyK5RUVFLQxDqchUXVtH8bEqSvysD/rhugJu+fdq5/76vSUYY1/w2vFVKV9au7eMt7WtvP4WGmOeAZ4BGDNmjP6mqnZl3vvreW25vR5025TBbs0qZVU1JMXZuPGVlQD8clw/dh48xk2vruSe848nMdbGkMzUkMStIkdLk3uhiGQaYwpEJBM4YJXnA71dzssCPJcmV6qd+2j9fuf22yvzuXFCf77adpCszkmc/cgXbud+urmQhxduBWDe+/bpfS8ZrQN3lH8tbZb5AJhlbc8C3ncpv1xEEkQkBxgILA8sRKWiy6rdhzjs0hzzQ9ExVu4+zM+fX+6R2AFeWJrH1ON7uJW9ucK+UPStkwax7I6JwQ1YRaRGa+4i8howAegqIvnAn4D5wBsici2wG7gEwBizQUTeADYCNcBNxhjv62cp1U79/DnP+s5FT3/j5Uy7H49VUeZjGbpJQ7vTvWNiq8Wmokejyd0Yc4WPQ16rC8aY+4H7AwlKqWiWkZrgXEGoKcYO6ELB4XKvx+JjdRyi8k5/M5RqYz8ctK8gNHt8P9bMm+xxfOyALs7t4VmdKCmvZtuBo17vldU5yWu5UprclQqRO6Yd53UWx4yUBHY8MI1N90ylf0YKP7gsJ+eqT3pyRKympEJDJw5TKgROybEvH2eL8ew9nJYcjy1GSIq30TEpjrIq9/b2OJtwUna629zmSjWkyV2pNlBVU8egOz9y7i/b2XDQN3RNiefg0SoS4uo/UKd5WVXpd5MHc/2Z/YMTqIoamtyVagNPf77Dbf+u84Z6nHPwqH3yr8rqOmeZ6/J5F47qxZTjezB5aPcgRamiiSZ3pYKsrs7w2OKtbmWujTFv33A6RaWVrNp9iL9/+QNnD6lfAs+15n77lCH06KTdHlXTaHJXKsgKjlR4lHVNTXBuj+5rnzH7nOO6Mfn47ozum+48lpYU79xO9bOEnlINaW8ZpYKovKqWl7/d5VH+k+E9PcpibTFuiR3cE3pyFK+2pFqfJnelgujvX+7gb1/saPxEH07o1cm5LQ1XiFbKD03uSgWR6xwyo6xFnR+7bLiPsz0lxtm4bcpgJulLVNVM2oinVCuprTNc99L3nJSTzkMfb2H6iZnO6QH6ZXTgretPJ8ZLv/bG6CpLqiU0uSvVSv79/R4+21LEZ1vsi88sWFfgPPbp7yaEKCrVXmmzjFKtZGNBSahDUMpJk7tSraRbqvZBV+FDk7tSreRDqxnmipP7hDgSpTS5K9VqNu8vBeDBC09kxZ3nhDga1d7pC1WlWsHX2w4CMHOEfXBSl5QEPvj1WGJjYhjcQxezVm1Pk7tSreCq55YB0LlD/XQBw7LSQhSNUtoso1SLLd1+kNH3LuJwWZWzTNvbVbjQmrtSLXTls/ba+ldWkwzAoO7aBKPCQ0A1dxG5RUQ2iMh6EXlNRBJFJF1EFonINutr59YKVqlwVFlT1/hJSrWxFid3EekF/A8wxhhzAmADLgfmAEuMMQOBJda+UlHr0DF7s8yNE3R1JBU+Am1zjwWSRCQWSAb2AecDL1nHXwJmBvg9lAo7xhjn9u7iMgD6ZaSEKhylPLQ4uRtj9gIPA7uBAqDEGLMQ6G6MKbDOKQC6ebteRGaLSK6I5BYVFbU0DKVC4t1Ve53bL39nn6/d9cWqUqEWSLNMZ+y19BygJ9BBRK5q6vXGmGeMMWOMMWMyMjJaGoZSIbFi1yGPspLyai9nKhUagTTLnAPsNMYUGWOqgXeA04FCEckEsL4eCDxMpcLLgG6eTTDdXJbOUyrUAknuu4FTRSRZ7EvETAQ2AR8As6xzZgHvBxaiUuHnz//ZCMCd049zll16Uu9QhaOUhxb3czfGLBORt4CVQA2wCngGSAHeEJFrsf8BuKQ1AlUqFJZsKuTal3KZMbwn/1mzjxeuPomzBte/RrpuXD8mD+1BVW0tCbG6xqkKHwENYjLG/An4U4PiSuy1eKUi3v0LNgHwnzX7AHhs0VbOGtyN2BjhtP5dAOjTJTlk8Snli04/oJQfPxw85rZffKyK2jqDAXp2SgpNUEo1gSZ3pXzYX1LhUTY8K438Q2XU1hlOyOoUgqiUahpN7kr5cMFTS53befOn0zUlgQXrClibb19Or39Gh1CFplSjNLkr5UOczf7P4/2bxgJw8GglAL95bRUAA3REqgpjOiukUj6M7tuZ2jrD8N5pXo93So5r24CUagatuSvloqa2jlW77aNP8348Rmpiff3njmlD3M7Vro8qnGnNXSkXb67IZ+4765g4pBurdh92OzZ7fH8E4f4PN4UmOKWaQWvuSrnYfuAoAEs2e58147pxORyX2ZEnLh/RhlEp1Xxac1fKxXNf73Tb337/uW77IsJHN49ry5CUahGtuSvlw7iBXYm16T8RFZm05q6UxbGi0iWjs7hwVJZzegGlIpFWS5TCvrLSxEe/AOCMgV01sauIp8ldKeDj9fsptmruvdN1IjAV+TS5KwXc8MpK5/aJvXTOGBX5NLmrds/R1g5w25TBzmkHlIpk+lus2r03V+xxbv/stL4hjESp1qPJXbVrFdW1lFbUAHDtGTmkJmgHMhUd9DdZtWtD7vrYuX3n9OOwLwesVOTTmrtqt0rKqt32NbGraBJQcheRNBF5S0Q2i8gmETlNRNJFZJGIbLO+dm6tYJVqTcPvWRjqEJQKmkBr7k8AHxtjhgDDgU3AHGCJMWYgsMTaVyqs7XxwWqhDUKpVtbjNXUQ6AuOBXwAYY6qAKhE5H5hgnfYS8Dnwh0CCVCpQ+YfKOON/P+Pi0Vms31vCvPOGOo8tvvVMbZJRUSeQF6r9gCLgBREZDqwAbga6G2MKAIwxBSLSzdvFIjIbmA3Qp0+fAMJQyrfcvGKOVtawtbAUgLdW5APw02eXAXDLOYMY0E2Xy1PRJ5BmmVhgFPC0MWYkcIxmNMEYY54xxowxxozJyMgIIAylvFu0sZCL//Ytv3jhe2d3x4aKj1W2cVRKtY1Akns+kG+MWWbtv4U92ReKSCaA9dX7qgdKBdkv/5nr3P7rp9u9njNzZK+2CkepNtXi5G6M2Q/sEZHBVtFEYCPwATDLKpsFvB9QhEo1057iMrLnLPB5/NwTeji3dR4ZFa0C7S3zG+AVEVkLjAAeAOYDk0RkGzDJ2leqzUz/y1fO7dumDHY79sAFJ/L0VaMBGNknTRfjUFEroBGqxpjVwBgvhyYGcl+lAtEzLYkj+0tJTYxl9vh+FJVW8uI3eTx22XAuGJkFQN786SGOUqng0ukHVNTZvN/eM2bd3VMA+NOMocwYnsmoPjqeTrUfmtxVVNlTXAZAz06JzjIRYXTf9FCFpFRIaIOjiirLdhYDMGfacSGORKnQ0uSuokrhkQoAJh3XPcSRKBVamtxVVCkqrSQ1MZakeFuoQ1EqpDS5q6jy47EquqYkhDoMpUJOk7uKKsXHKumcHBfqMJQKOU3uKmr8eLSSpdt/JL1DfKhDUSrkNLmrqDH6vsUALN6k0xkppcldRZ0bJvQPdQhKhZwmdxUVio9VObdvbzCfjFLtkSZ3FRUOlNr7t//fT0fpqkpKocldRYl3Vu4FwBajiV0p0OSuokRVTR0AZwzsGuJIlAoPmtxVxPvv2n28+E0eACkJOheeUqDJXUWBX7+6KtQhKBV2NLmrqPH8L7ytG6NU+6TJXUW0Y5U1zu2zh+hMkEo5aAOlChvbCku57p+5pCTEsmHfEbbedy7xsf7rH2v2HAbgvpkntEGESkUOTe4qLBSUlDPpsS/dytbtPdzoCko/fXYZAGcM0F4ySrkKuFlGRGwiskpE/mvtp4vIIhHZZn3VhSuVXzW1dZz24Kce5UWlVV7OrufaJNMnPbnV41IqkrVGm/vNwCaX/TnAEmPMQGCJta+UG2MMn285QFVNHQP++JGz/H8mDmTpnLMB2Lz/CKUV1Xy8voCSsmqPexworQTgoYuHEaODl5RyE1CzjIhkAdOB+4FbreLzgQnW9kvA58AfAvk+KrrU1LondIcbJvTn1kmDqKszADy+eBuPL97mPJ43f7rb+ev3lgDQOVmn+FWqoUBr7o8DtwN1LmXdjTEFANbXbt4uFJHZIpIrIrlFRUUBhqEiSdHRSo+y3ulJ3DppEIDPWvj7q/e67X+z4yAAJ2f7b5dXqj1qcXIXkfOAA8aYFS253hjzjDFmjDFmTEZGRkvDUBFkf0kFG/cdITfvkFv5zBE9+er2s4mz1f86rv/zFC4/qbfbeTe/vtpZWwd4bfkeADrpyktKeQikWWYs8BMRmQYkAh1F5F9AoYhkGmMKRCQT0JUT2rl9h8vJ7JTIqQ8uASDB6t649u7JVFbXkZHqueZpSkIs8y8axvyLhvHE4m08tngrAOf99WvW3j2ZolLP2r9Sql6La+7GmLnGmCxjTDZwOfCpMeYq4ANglnXaLOD9gKNUEeuTDfs5ff6n5Mz90FlWaU3y1TExzmtib+jmcwby+GUjnPsfri1g4iNfAHD3jKGtG7BSUSIYI1TnA5NEZBswydpX7Uh5Va1z+1cvt6jVzsPMkb1YedckAOa8s85Z/ouxOa1yf6WiTasMYjLGfI69VwzGmB+Bia1xXxV5lu8s5tK/f8vdM4Z6Tbxr5k3m+7xisrt2aPa9deFrpZpOR6iqFikpr2ZH0VFG9akfo2aM4ZMN+wFYsvkAF4zMAmDOuUMY3COVL7cW0TEplnOGts4cMJ/8dnyr3EepaKTJXTWqrs54dE885YHFVFTXsemeqSTF27j0b9+yPK/YefyrbQcZfs9CAAZkpHDW4G6cNdhrr9hmuXP6cfxlyTb+85sz6Nul+bV/pdoLTe5RrqqmjjibtHhd0RW7irno6W+5d+YJnJKTzofrCph1WjYV1faXoku3H6SgpNwtsTc0thXnfbluXD+uG9ev1e6nVLQSY0yoY2DMmDEmNzc31GFEvJKyao5V1bB+bwn/+/FmHrp4OBc9/Q1dU+LJvXNSi+6ZPWdBk8/t3jGBrM7J3DihP9e+ZP//2S+jA5/+bkKLvrdSyj8RWWGM8bqQgdbco8hlz3zL5v2lzv2Lnv4GgINHqyg+VtXkF5K3/Hs1763eS3P/7n95+1kkxNoAeH32qcTZYhjdV+eNUyoUdLGOKLE2/7BbYm9o1L2LWJdf4vO4w+THvuDdVe6JffGtZzq3f3F6NqP7dubpK0exZt5kenZKBOCiUVnOxA5war8umtiVCiGtuUeJnzy51Ll9zdgc5s0Yyr++28UZA7oy469fU1pZw4wnv/aYfAugtKKasx/5gpkjerK18KizPLtLMgv+ZxwdEmK5bcpgkuNtXN2ge+M3c7XXq1LhSNvco0BZVQ1D530CwJe3nUWfLu5zm9fWGfrfYR8hesXJfXjwwhOpqzPsOVRGUpyN91fv4/4P62dtPr1/F35z9kBO69+l7X4IpVSzaZt7lHtiiX1a3DnnDvFI7AC2GOHVX57CT/+xjNeW7+aiUb24+G/fOo8P6ZHqdv6rvzw1uAErpYJOk3uEKygp5/mvdwLwq/G+uwie3r++O6JrYgfYvL+U0X070zc9menDMoMTqFKqTekL1Qh38dPfUl1reOmakxvty/7Br8e67T966XDn9rQTM3n0shFMPK51Ro8qpUJLa+4R6qttRfzsueUAnJKTzpmDGp8Tf1D3VGIE6gxsvGcKyfGxnHtCJm+vzOeyBnOnK6Uimyb3CLF0+0GufHaZ12PP/Nzr+xQPiXE2fnjQvbdMUryNq07tG3B8Sqnwosk9zG0tLGXyY1/6PadTkq5EpJRyp8m9DWzcd4Rpf/kKgOnDMnnyipEs21lMTtcOdO+Y6HH+gSMV/Pm/G1mRd4j9Ryrcjr1w9Ulc/cL3ALz6y1PcZmVUSikH7efuxcGjlXRKinNb0zOQe425b7FbWVKcjfJq+4IWn/7uTPplpDiPfbq5kGte9HwWD108jPNH9CQh1oYxpsUTgSmlooe/fu7aW6aBV5ftZsx9ixn4x48oKat2O7Z4YyHvrMynoroWYwwFJeV+71VRXeuW2OedZ18SzpHYAX735hr2FJdhjGFrYalbYh87oAszR/RkzbzJXDqmt3N4vyZ2pVRj2nWzzFXPLuPr7Qe567yh7DtcznNWf3GH4fcs5LR+XXjo4mFMeuwL5zS3t76xhtP7d+GbHT8CsPCW8fTPSMFmzXlujMEYeGThFue9Nt87lcQ4G3GxMdz13noA0pLjWLX7MOMe+oyenRLZV2JvghndtzNvXX+aJnGlVItFfLPM/pIKuqUmeCwm0ZjDZVWMuGdRi76nNzNH9OTxy0dijOG8v37Nhn1HnMfmnjuEX53Z3+OakvJqhv95oUf5zgenaWJXSjUqaptl9hSXceqDS3jys+3NvnbnwWMeZb+fPIiVd00ib/508uZP5y6rGcXhhgn92Xrfuc5919kS31u9j/kfbSZn7oduif2iUVleEzvYe7k8fMlwUhPtH6DibTEsnXO2JnalVMBaXHMXkd7AP4EeQB3wjDHmCRFJB/4NZAN5wKXGmEP+7tXSmrtjlaCRfdJ490b76EtvLxtX7j7EiKw0Z+2+8EgFpzywBIC3bziNf367i2vPyGFYVprbdTW1dZx0/2I6JcXx0c3jSYq3t3nvKS7jaGUNx2V2pLKmloc+3uLRpJPVOYlrxuZwzRmei0R7c7SyhqQ4m7NpRymlGhOsicNqgN8ZY1aKSCqwQkQWAb8Alhhj5ovIHGAO8IcAvo9Pjt4sNbX2P1CnPLCYwiOVzh4oxhhy5n7oPH9UnzTmzTiemf9nnx43RmB033RG9033ev9YWwyr5k32KO+dXj85V0KsjTumHceCtQXObouOdUWbIyWhXb/+UEq1shZnFGNMAVBgbZeKyCagF3A+MME67SXgc4Kc3Ktr69j9YxmFRyoBOPuRL7h54kBG9ElzO3/l7sPOxA6wdM7ZrRKHLUb4Zs7ZfLi+gAmDuzU7sSulVGtrleqiiGQDI4FlQHcr8WOMKRARr0vei8hsYDZAnz59WvR942z2JozN+0u57a01bscc0+ACrJ43idKKGs594iuOVtYAeF20IhAxMcJ5w3q26j2VUqqlAk7uIpICvA381hhzpKkvA40xzwDPgL3NvYXf27m9bGcxACvuPIcb/rWS5Xn2/bEDupCWHE9acjzr/zyFY5U1xMdG9HtkpZRqVEDJXUTisCf2V4wx71jFhSKSadXaM4EDgQbpi7d3wV1SEnjj+tNYsLaABev28dSVo92Od9C2baVUO9DiKqzYq83PAZuMMY+6HPoAmGVtzwLeb3l4/vnr6TN9WKZHYldKqfYikGrsWOBnwDoRWW2V3QHMB94QkWuB3cAlAUXoh2tqH9E7jVsnDQrWt1JKqYgSSG+ZrwFfDewTW3rf5qhzqbm/d9NYP2cqpVT7EtFvFsNg5gSllApLUZHce6UlhTYQpZQKMxGd3B3NMvNmDG3kTKWUal8iOrk7xOhEW0op5Saik7uj5q6pXSml3EV0cne0ucdE9E+hlFKtL6LTYqekOKad2INuqZ6LTCulVHsW0WPxs7t20FGoSinlRUTX3JVSSnmnyV0ppaKQJnellIpCmtyVUioKaXJXSqkopMldKaWikCZ3pZSKQprclVIqCom/peraLAiRImBXALfoChxspXCCKVLiBI01WDTW4GivsfY1xmR4OxAWyT1QIpJrjBkT6jgaEylxgsYaLBprcGisnrRZRimlopAmd6WUikLRktyfCXUATRQpcYLGGiwaa3BorA1ERZu7Ukopd9FSc1dKKeVCk7tSSkWhiE7uIjJVRLaIyHYRmRPqeABEJE9E1onIahHJtcrSRWSRiGyzvnZ2OX+uFf8WEZkS5NieF5EDIrLepazZsYnIaOtn3C4ifxFp/RXKfcR6t4jstZ7tahGZFupYRaS3iHwmIptEZIOI3GyVh91z9RNrOD7XRBFZLiJrrFj/bJWH43P1FWton6sxJiL/A2zADqAfEA+sAYaGQVx5QNcGZQ8Bc6ztOcD/WttDrbgTgBzr57EFMbbxwChgfSCxAcuB07CvTf4RcG4bxXo38Hsv54YsViATGGVtpwJbrXjC7rn6iTUcn6sAKdZ2HLAMODVMn6uvWEP6XCO55n4ysN0Y84Mxpgp4HTg/xDH5cj7wkrX9EjDTpfx1Y0ylMWYnsB37zxUUxpgvgeJAYhORTKCjMeZbY/9t/KfLNcGO1ZeQxWqMKTDGrLS2S4FNQC/C8Ln6idWXUMZqjDFHrd046z9DeD5XX7H60iaxRnJy7wXscdnPx/8valsxwEIRWSEis62y7saYArD/AwO6WeXh8DM0N7Ze1nbD8rbyaxFZazXbOD6Sh0WsIpINjMRecwvr59ogVgjD5yoiNhFZDRwAFhljwva5+ogVQvhcIzm5e2uLCod+nWONMaOAc4GbRGS8n3PD9WcA37GFMuangf7ACKAAeMQqD3msIpICvA381hhzxN+pPmIKZaxh+VyNMbXGmBFAFvaa7Ql+Tg/HWEP6XCM5uecDvV32s4B9IYrFyRizz/p6AHgXezNLofWRC+vrAev0cPgZmhtbvrXdsDzojDGF1j+iOuAf1DdhhTRWEYnDnixfMca8YxWH5XP1Fmu4PlcHY8xh4HNgKmH6XL3FGurnGsnJ/XtgoIjkiEg8cDnwQSgDEpEOIpLq2AYmA+utuGZZp80C3re2PwAuF5EEEckBBmJ/odKWmhWb9VG4VEROtd7k/9zlmqBy/KO2XID92YY0Vuu+zwGbjDGPuhwKu+fqK9Ywfa4ZIpJmbScB5wCbCc/n6jXWkD/XQN8Uh/I/YBr2N/47gD+GQTz9sL8FXwNscMQEdAGWANusr+ku1/zRin8LQeh10iC+17B/PKzGXku4tiWxAWOsX9QdwJNYI53bINaXgXXAWusfSGaoYwXOwP7ReS2w2vpvWjg+Vz+xhuNzHQassmJaD8xr6b+lEMYa0ueq0w8opVQUiuRmGaWUUj5ocldKqSikyV0ppaKQJnellIpCmtyVUioKaXJXSqkopMldKaWi0P8H7+1kbNTE02cAAAAASUVORK5CYII=\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"tags":[],"id":"iIipIkntfuWP","outputId":"86957758-02a4-44d6-bc47-93d8ddb8cac3"},"source":["with T.no_grad():\n","    total_reward, total_moves = 0,0\n","    done = False\n","    observation = env.reset()\n","\n","    while not done:\n","        time.sleep(0.05)\n","        env.render()\n","\n","        # e_GREEDY ACTION\n","        action = agent.get_action(observation, greedy=True)\n","        observation_, reward, done, _ = env.step(action)\n","\n","        total_reward += reward\n","        total_moves += 1\n","\n","        observation = observation_\n","    print(\"RWD: \",total_reward,\"\\tLEN: \",total_moves)\n","    # env.close()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["RWD:  251.89999999999947 \tLEN:  202\n"],"name":"stdout"}]}]}